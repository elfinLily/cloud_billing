# -*- coding: utf-8 -*-
"""
ì‚¬ìš©ë¥  ì¶”ì • ëª¨ë¸

GCPì—ì„œ í•™ìŠµí•œ íŒ¨í„´ì„ ê¸°ë°˜ìœ¼ë¡œ AWS ë¦¬ì†ŒìŠ¤ì˜ CPU/Memory ì‚¬ìš©ë¥ ì„ ì¶”ì •í•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
import json
from pathlib import Path
import sys

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / 'data_processing'))
from pipeline_base import PipelineBase

class UsageEstimator(PipelineBase):
    """
    ì‚¬ìš©ë¥  ì¶”ì • í´ë˜ìŠ¤
    
    ì£¼ìš” ê¸°ëŠ¥:
    1. GCP í•™ìŠµ íŒ¨í„´ ë¡œë“œ
    2. AWS-GCP ì„œë¹„ìŠ¤ ë§¤ì¹­
    3. CPU/Memory ì‚¬ìš©ë¥  ì¶”ì •
    4. ë¶ˆí™•ì‹¤ì„± ì ìˆ˜ ê³„ì‚°
    """
    
    def __init__(self, config_path='config/focus_config.yaml'):
        """
        ì´ˆê¸°í™”
        
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        super().__init__(config_path)
        
        # ê²½ë¡œ ì„¤ì •
        self.pattern_path = Path('results/transfer_learning/gcp_learned_patterns.json')
        self.mapping_path = Path('config/service_mapping.yaml')
        
        # ê²°ê³¼ ì €ì¥
        self.gcp_patterns = None
        self.service_mapping = None
    
    
    def load(self):
        """
        GCP í•™ìŠµ íŒ¨í„´ ë¡œë“œ
        
        Returns:
            self
        """
        self.print_step("GCP íŒ¨í„´ ë¡œë“œ", f"{self.pattern_path}")
        
        if not self.pattern_path.exists():
            self.print_error(f"íŒ¨í„´ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.pattern_path}")
            raise FileNotFoundError(f"{self.pattern_path}")
        
        # JSON ë¡œë“œ
        with open(self.pattern_path, 'r', encoding='utf-8') as f:
            self.gcp_patterns = json.load(f)
        
        self.print_success("íŒ¨í„´ ë¡œë“œ ì™„ë£Œ")
        print(f"   ğŸ“Š ì„œë¹„ìŠ¤: {len(self.gcp_patterns)}ê°œ")
        
        return self
    
    
    def _load_service_mapping(self):
        """
        AWS-GCP ì„œë¹„ìŠ¤ ë§¤ì¹­ í…Œì´ë¸” ë¡œë“œ
        
        ë§¤ì¹­ íŒŒì¼ì´ ì—†ìœ¼ë©´ ìë™ ìƒì„±
        
        Returns:
            self
        """
        print("\nğŸ”— ì„œë¹„ìŠ¤ ë§¤ì¹­ í…Œì´ë¸” ë¡œë“œ ì¤‘...")
        
        if not self.mapping_path.exists():
            self.print_warning("ë§¤ì¹­ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ìë™ ìƒì„±í•©ë‹ˆë‹¤.")
            self._create_default_mapping()
        
        # YAML ë¡œë“œ
        import yaml
        with open(self.mapping_path, 'r', encoding='utf-8') as f:
            self.service_mapping = yaml.safe_load(f)
        
        mapping_count = len(self.service_mapping.get('mappings', {}))
        
        self.print_success("ë§¤ì¹­ í…Œì´ë¸” ë¡œë“œ ì™„ë£Œ")
        print(f"   ğŸ“Š ë§¤ì¹­: {mapping_count}ê°œ")
        
        return self
    
    
    def _create_default_mapping(self):
        """
        ê¸°ë³¸ AWS-GCP ì„œë¹„ìŠ¤ ë§¤ì¹­ í…Œì´ë¸” ìƒì„±
        """
        default_mapping = {
            'mappings': {
                # Compute
                'Amazon Elastic Compute Cloud': 'Compute Engine',
                'AWS Lambda': 'Cloud Functions',
                'Amazon Elastic Container Service': 'Cloud Run',
                'Amazon Elastic Kubernetes Service': 'Kubernetes Engine',
                
                # Storage
                'Amazon Simple Storage Service': 'Cloud Storage',
                'Amazon Elastic Block Store': 'Persistent Disk',
                'Amazon Elastic File System': 'Cloud Filestore',
                
                # Database
                'Amazon Relational Database Service': 'Cloud SQL',
                'Amazon DynamoDB': 'Cloud Firestore',
                'Amazon ElastiCache': 'Cloud Memorystore',
                
                # Networking
                'Amazon Virtual Private Cloud': 'Virtual Private Cloud',
                'Elastic Load Balancing': 'Cloud Load Balancing',
                'Amazon CloudFront': 'Cloud CDN',
                
                # Analytics
                'Amazon Athena': 'BigQuery',
                'Amazon EMR': 'Cloud Dataproc',
                'Amazon Kinesis': 'Cloud Pub/Sub',
                
                # AI/ML
                'Amazon SageMaker': 'Vertex AI',
                'Amazon Rekognition': 'Cloud Vision API',
                'Amazon Comprehend': 'Cloud Natural Language',
                
                # Monitoring
                'AmazonCloudWatch': 'Cloud Monitoring',
                'AWS CloudTrail': 'Cloud Logging',
            },
            'fallback_strategy': 'use_global_average'
        }
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.ensure_dir(self.mapping_path.parent)
        
        # YAML ì €ì¥
        import yaml
        with open(self.mapping_path, 'w', encoding='utf-8') as f:
            yaml.dump(default_mapping, f, 
                     default_flow_style=False, 
                     allow_unicode=True,
                     sort_keys=False)
        
        print(f"   âœ… ê¸°ë³¸ ë§¤ì¹­ í…Œì´ë¸” ìƒì„±: {self.mapping_path}")
        
        self.service_mapping = default_mapping
    
    
    def estimate_single(self, aws_service_name, aws_cost=None):
        """
        ë‹¨ì¼ AWS ì„œë¹„ìŠ¤ì˜ ì‚¬ìš©ë¥  ì¶”ì •
        
        Args:
            aws_service_name (str): AWS ì„œë¹„ìŠ¤ëª…
            aws_cost (float): AWS ë¹„ìš© (ì„ íƒ)
        
        Returns:
            dict: ì¶”ì • ê²°ê³¼
                - cpu_mean: CPU í‰ê·  ì‚¬ìš©ë¥ 
                - cpu_std: CPU í‘œì¤€í¸ì°¨
                - memory_mean: Memory í‰ê·  ì‚¬ìš©ë¥ 
                - memory_std: Memory í‘œì¤€í¸ì°¨
                - confidence: ì‹ ë¢°ë„ (0-1)
                - matched_gcp_service: ë§¤ì¹­ëœ GCP ì„œë¹„ìŠ¤
                - method: ì¶”ì • ë°©ë²•
        """
        # 1. AWS â†’ GCP ì„œë¹„ìŠ¤ ë§¤ì¹­
        gcp_service = self._match_service(aws_service_name)
        
        # 2. GCP íŒ¨í„´ ì¡°íšŒ
        if gcp_service and gcp_service in self.gcp_patterns:
            pattern = self.gcp_patterns[gcp_service]
            method = 'exact_match'
            confidence = 1.0
        else:
            # Fallback: ì „ì²´ í‰ê·  ì‚¬ìš©
            pattern = self._get_global_average()
            method = 'global_average'
            confidence = 0.3
            gcp_service = 'Global Average'
        
        # 3. ì¶”ì •ê°’ ìƒì„±
        result = {
            'aws_service': aws_service_name,
            'matched_gcp_service': gcp_service,
            'method': method,
            'confidence': confidence
        }
        
        # CPU ì¶”ì •
        if 'cpu' in pattern:
            result['cpu_mean'] = pattern['cpu']['mean']
            result['cpu_std'] = pattern['cpu']['std']
            result['cpu_median'] = pattern['cpu']['median']
            result['cpu_min'] = pattern['cpu']['min']
            result['cpu_max'] = pattern['cpu']['max']
        
        # Memory ì¶”ì •
        if 'memory' in pattern:
            result['memory_mean'] = pattern['memory']['mean']
            result['memory_std'] = pattern['memory']['std']
            result['memory_median'] = pattern['memory']['median']
            result['memory_min'] = pattern['memory']['min']
            result['memory_max'] = pattern['memory']['max']
        
        return result
    
    
    def _match_service(self, aws_service_name):
        """
        AWS ì„œë¹„ìŠ¤ë¥¼ GCP ì„œë¹„ìŠ¤ë¡œ ë§¤ì¹­
        
        Args:
            aws_service_name (str): AWS ì„œë¹„ìŠ¤ëª…
        
        Returns:
            str: ë§¤ì¹­ëœ GCP ì„œë¹„ìŠ¤ëª… (ì—†ìœ¼ë©´ None)
        """
        if not self.service_mapping:
            return None
        
        mappings = self.service_mapping.get('mappings', {})
        
        # ì •í™•íˆ ë§¤ì¹­
        if aws_service_name in mappings:
            return mappings[aws_service_name]
        
        # ë¶€ë¶„ ë§¤ì¹­ (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
        aws_lower = aws_service_name.lower()
        for aws_key, gcp_value in mappings.items():
            if aws_key.lower() in aws_lower or aws_lower in aws_key.lower():
                return gcp_value
        
        return None
    
    
    def _get_global_average(self):
        """
        ì „ì²´ GCP ì„œë¹„ìŠ¤ì˜ í‰ê·  íŒ¨í„´ ê³„ì‚°
        
        Returns:
            dict: í‰ê·  íŒ¨í„´
        """
        if not self.gcp_patterns:
            return {}
        
        # CPU í‰ê· 
        cpu_means = []
        cpu_stds = []
        
        for pattern in self.gcp_patterns.values():
            if 'cpu' in pattern:
                cpu_means.append(pattern['cpu']['mean'])
                cpu_stds.append(pattern['cpu']['std'])
        
        # Memory í‰ê· 
        mem_means = []
        mem_stds = []
        
        for pattern in self.gcp_patterns.values():
            if 'memory' in pattern:
                mem_means.append(pattern['memory']['mean'])
                mem_stds.append(pattern['memory']['std'])
        
        result = {}
        
        if cpu_means:
            result['cpu'] = {
                'mean': np.mean(cpu_means),
                'std': np.mean(cpu_stds),
                'median': np.median(cpu_means),
                'min': np.min(cpu_means),
                'max': np.max(cpu_means)
            }
        
        if mem_means:
            result['memory'] = {
                'mean': np.mean(mem_means),
                'std': np.mean(mem_stds),
                'median': np.median(mem_means),
                'min': np.min(mem_means),
                'max': np.max(mem_means)
            }
        
        return result
    
    
    def estimate_batch(self, aws_services):
        """
        ì—¬ëŸ¬ AWS ì„œë¹„ìŠ¤ì˜ ì‚¬ìš©ë¥  ì¼ê´„ ì¶”ì •
        
        Args:
            aws_services (list): AWS ì„œë¹„ìŠ¤ëª… ë¦¬ìŠ¤íŠ¸
        
        Returns:
            pd.DataFrame: ì¶”ì • ê²°ê³¼
        """
        results = []
        
        print(f"\n{'='*100}")
        print(f"ğŸ”„ ì¼ê´„ ì¶”ì • ì‹œì‘: {len(aws_services)}ê°œ ì„œë¹„ìŠ¤")
        print(f"{'='*100}")
        
        for i, service in enumerate(aws_services, 1):
            if i % 10 == 0 or i == len(aws_services):
                print(f"   ì§„í–‰: {i}/{len(aws_services)}...", end='\r')
            
            result = self.estimate_single(service)
            results.append(result)
        
        print()  # ì¤„ë°”ê¿ˆ
        
        df_results = pd.DataFrame(results)
        
        self.print_success(f"ì¼ê´„ ì¶”ì • ì™„ë£Œ: {len(results)}ê°œ")
        
        # í†µê³„ ì¶œë ¥
        self._print_batch_summary(df_results)
        
        return df_results
    
    
    def _print_batch_summary(self, df_results):
        """ì¼ê´„ ì¶”ì • ê²°ê³¼ ìš”ì•½"""
        print(f"\n{'='*100}")
        print("ğŸ“Š ì¶”ì • ê²°ê³¼ ìš”ì•½")
        print(f"{'='*100}")
        
        # ì¶”ì • ë°©ë²•ë³„ í†µê³„
        method_counts = df_results['method'].value_counts()
        print(f"\n   ğŸ“Œ ì¶”ì • ë°©ë²•:")
        for method, count in method_counts.items():
            pct = count / len(df_results) * 100
            print(f"      â€¢ {method:20s}: {count:4,}ê±´ ({pct:5.1f}%)")
        
        # ì‹ ë¢°ë„ í†µê³„
        print(f"\n   ğŸ“Œ ì‹ ë¢°ë„:")
        print(f"      â€¢ í‰ê· : {df_results['confidence'].mean():.2f}")
        print(f"      â€¢ ì¤‘ì•™ê°’: {df_results['confidence'].median():.2f}")
        print(f"      â€¢ ìµœì†Œ: {df_results['confidence'].min():.2f}")
        print(f"      â€¢ ìµœëŒ€: {df_results['confidence'].max():.2f}")
        
        # CPU ì‚¬ìš©ë¥  í†µê³„
        if 'cpu_mean' in df_results.columns:
            print(f"\n   ğŸ“Œ ì¶”ì • CPU ì‚¬ìš©ë¥ :")
            print(f"      â€¢ í‰ê· : {df_results['cpu_mean'].mean()*100:.2f}%")
            print(f"      â€¢ ì¤‘ì•™ê°’: {df_results['cpu_mean'].median()*100:.2f}%")
            print(f"      â€¢ ìµœì†Œ: {df_results['cpu_mean'].min()*100:.2f}%")
            print(f"      â€¢ ìµœëŒ€: {df_results['cpu_mean'].max()*100:.2f}%")
        
        # Memory ì‚¬ìš©ë¥  í†µê³„
        if 'memory_mean' in df_results.columns:
            print(f"\n   ğŸ“Œ ì¶”ì • Memory ì‚¬ìš©ë¥ :")
            print(f"      â€¢ í‰ê· : {df_results['memory_mean'].mean()*100:.2f}%")
            print(f"      â€¢ ì¤‘ì•™ê°’: {df_results['memory_mean'].median()*100:.2f}%")
            print(f"      â€¢ ìµœì†Œ: {df_results['memory_mean'].min()*100:.2f}%")
            print(f"      â€¢ ìµœëŒ€: {df_results['memory_mean'].max()*100:.2f}%")
        
        print(f"\n{'='*100}")
    
    
    def process(self):
        """
        ë”ë¯¸ process (PipelineBase í˜¸í™˜)
        
        Returns:
            self
        """
        return self
    
    
    def save(self):
        """
        ë”ë¯¸ save (PipelineBase í˜¸í™˜)
        
        Returns:
            self
        """
        return self
    
    
    def run(self):
        """
        ì´ˆê¸°í™” ì‹¤í–‰
        
        Returns:
            self
        """
        return self.load()._load_service_mapping()


# ==================== ë©”ì¸ ì‹¤í–‰ ====================
if __name__ == "__main__":
    
    print("\nğŸš€ ì‚¬ìš©ë¥  ì¶”ì • ëª¨ë¸ í…ŒìŠ¤íŠ¸")
    print("="*100)
    
    estimator = UsageEstimator('config/focus_config.yaml')
    estimator.run()
    
    # ë‹¨ì¼ ì¶”ì • í…ŒìŠ¤íŠ¸
    print("\n" + "="*100)
    print("ğŸ§ª ë‹¨ì¼ ì„œë¹„ìŠ¤ ì¶”ì • í…ŒìŠ¤íŠ¸")
    print("="*100)
    
    test_services = [
        'Amazon Elastic Compute Cloud',
        'Amazon Simple Storage Service',
        'Amazon Relational Database Service',
        'AmazonCloudWatch'
    ]
    
    for service in test_services:
        result = estimator.estimate_single(service)
        print(f"\nğŸ“Š {service}")
        print(f"   â†’ GCP: {result['matched_gcp_service']}")
        print(f"   â†’ ë°©ë²•: {result['method']}")
        print(f"   â†’ ì‹ ë¢°ë„: {result['confidence']:.2f}")
        if 'cpu_mean' in result:
            print(f"   â†’ CPU: {result['cpu_mean']*100:.2f}%")
        if 'memory_mean' in result:
            print(f"   â†’ Memory: {result['memory_mean']*100:.2f}%")
    
    print("\n" + "="*100)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")