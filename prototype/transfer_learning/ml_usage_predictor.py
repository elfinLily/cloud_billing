# -*- coding: utf-8 -*-
"""
ML ê¸°ë°˜ ì‚¬ìš©ë¥  ì˜ˆì¸¡ ëª¨ë¸ (v2)

resource_grouped.csvë¥¼ ì‚¬ìš©í•˜ì—¬:
1. GCP ë°ì´í„° (AvgCPUUsage, AvgMemoryUsage ìˆìŒ) â†’ í•™ìŠµ
2. AWS ë°ì´í„° (ì‚¬ìš©ë¥  ì—†ìŒ) â†’ ì˜ˆì¸¡

RandomForest íšŒê·€ ëª¨ë¸ ì‚¬ìš©
"""

import pandas as pd
import numpy as np
import yaml
import json
import joblib
from pathlib import Path
from sklearn.ensemble import RandomForestRegressor
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_absolute_error, r2_score
import sys

# ============================================================
# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
# ============================================================
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / 'data_processing'))

from pipeline_base import PipelineBase


class MLUsagePredictorV2(PipelineBase):
    """
    ML ê¸°ë°˜ ì‚¬ìš©ë¥  ì˜ˆì¸¡ í´ë˜ìŠ¤ (v2)
    
    ë°ì´í„° íë¦„:
    1. resource_grouped.csv ë¡œë“œ (GCP + AWS í†µí•©)
    2. ProviderNameìœ¼ë¡œ GCP/AWS ë¶„ë¦¬
    3. GCP ë°ì´í„°ë¡œ í•™ìŠµ (AvgCPUUsage, AvgMemoryUsage)
    4. AWS ë°ì´í„°ì— ì ìš©í•˜ì—¬ ì‚¬ìš©ë¥  ì˜ˆì¸¡
    5. ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ íƒì§€
    """
    
    def __init__(self, config_path='config/focus_config.yaml'):
        """
        ì´ˆê¸°í™”
        
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ (configì—ì„œ ëª¨ë“  ê²½ë¡œ ì½ìŒ)
        """
        super().__init__(config_path)
        
        # ============================================================
        # ê²½ë¡œ ì„¤ì • (config ê¸°ë°˜)
        # ============================================================
        data_config = self.config['data']
        self.input_path = Path(data_config['resource_grouped_output'])  # í•µì‹¬ ë³€ê²½!
        self.model_output_dir = Path('results/transfer_learning/models')
        self.result_output_path = Path('results/transfer_learning/ml_predictions_v2.csv')
        
        # ============================================================
        # ì„ê³„ê°’ ì„¤ì • (config ê¸°ë°˜)
        # ============================================================
        thresholds = self.config['thresholds']['over_provisioning']
        self.cpu_threshold = thresholds['cpu_threshold']      # 0.30
        self.memory_threshold = thresholds['memory_threshold']  # 0.30
        
        # ============================================================
        # ëª¨ë¸ ê´€ë ¨ ë³€ìˆ˜
        # ============================================================
        self.cpu_model = None
        self.memory_model = None
        self.label_encoders = {}
        self.scaler = StandardScaler()
        
        # ============================================================
        # ë°ì´í„° ë³€ìˆ˜
        # ============================================================
        self.df_all = None       # ì „ì²´ ë°ì´í„°
        self.df_gcp = None       # GCP ë°ì´í„° (í•™ìŠµìš©)
        self.df_aws = None       # AWS ë°ì´í„° (ì˜ˆì¸¡ ëŒ€ìƒ)
        self.df_predictions = None  # ì˜ˆì¸¡ ê²°ê³¼
        
        # ============================================================
        # Feature ì„¤ì •
        # ============================================================
        self.categorical_cols = ['ServiceName']
        self.numerical_cols = ['TotalHourlyCost', 'HourOfDay', 'DayOfWeek']
        self.feature_cols = []
    
    
    def load(self):
        """
        resource_grouped.csv ë¡œë“œ ë° GCP/AWS ë¶„ë¦¬
        
        Returns:
            self (ë©”ì„œë“œ ì²´ì´ë‹)
        """
        self.print_step("ë°ì´í„° ë¡œë”©", f"{self.input_path}")
        
        if not self.input_path.exists():
            self.print_error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.input_path}")
            raise FileNotFoundError(f"{self.input_path}")
        
        # CSV ë¡œë“œ
        self.df_all = pd.read_csv(self.input_path)
        
        self.print_success("ë¡œë“œ ì™„ë£Œ")
        print(f"   ğŸ“Š ì „ì²´ ë ˆì½”ë“œ: {len(self.df_all):,}ê±´")
        print(f"   ğŸ“‹ ì»¬ëŸ¼: {list(self.df_all.columns)}")
        
        # ============================================================
        # ProviderNameìœ¼ë¡œ GCP/AWS ë¶„ë¦¬
        # ============================================================
        print(f"\n   ğŸ”€ Providerë³„ ë¶„ë¦¬ ì¤‘...")
        
        self.df_gcp = self.df_all[self.df_all['ProviderName'] == 'GCP'].copy()
        self.df_aws = self.df_all[self.df_all['ProviderName'] == 'AWS'].copy()
        
        print(f"   â˜ï¸  GCP: {len(self.df_gcp):,}ê±´")
        print(f"   â˜ï¸  AWS: {len(self.df_aws):,}ê±´")
        
        # ============================================================
        # GCP ë°ì´í„°ì— CPU/Memory ìˆëŠ”ì§€ í™•ì¸
        # ============================================================
        if 'AvgCPUUsage' not in self.df_gcp.columns:
            self.print_error("GCP ë°ì´í„°ì— AvgCPUUsage ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤!")
            raise ValueError("AvgCPUUsage ì»¬ëŸ¼ í•„ìš”")
        
        if 'AvgMemoryUsage' not in self.df_gcp.columns:
            self.print_error("GCP ë°ì´í„°ì— AvgMemoryUsage ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤!")
            raise ValueError("AvgMemoryUsage ì»¬ëŸ¼ í•„ìš”")
        
        self.print_success("GCP ë°ì´í„°ì— CPU/Memory ì‚¬ìš©ë¥  í™•ì¸ë¨")
        
        return self
    
    
    def _extract_features(self, df):
        """
        Feature ì¶”ì¶œ
        
        Args:
            df: ì›ë³¸ DataFrame
        
        Returns:
            DataFrame: Feature DataFrame
        """
        features = pd.DataFrame()
        
        # 1. ServiceName (ê·¸ëŒ€ë¡œ ì‚¬ìš©)
        features['ServiceName'] = df['ServiceName'].fillna('Unknown')
        
        # 2. TotalHourlyCost
        features['TotalHourlyCost'] = pd.to_numeric(
            df['TotalHourlyCost'], errors='coerce'
        ).fillna(0)
        
        # 3. HourOfDay, DayOfWeek (HourlyTimestampì—ì„œ ì¶”ì¶œ)
        if 'HourlyTimestamp' in df.columns:
            try:
                timestamps = pd.to_datetime(df['HourlyTimestamp'], errors='coerce')
                features['HourOfDay'] = timestamps.dt.hour.fillna(12)
                features['DayOfWeek'] = timestamps.dt.dayofweek.fillna(3)
            except:
                features['HourOfDay'] = 12
                features['DayOfWeek'] = 3
        else:
            features['HourOfDay'] = 12
            features['DayOfWeek'] = 3
        
        return features
    
    
    def _encode_features(self, features, fit=True):
        """
        Feature ì¸ì½”ë”© (LabelEncoder + StandardScaler)
        
        Args:
            features: Feature DataFrame
            fit: ì¸ì½”ë”/ìŠ¤ì¼€ì¼ëŸ¬ í•™ìŠµ ì—¬ë¶€
        
        Returns:
            numpy array: ì¸ì½”ë”©ëœ Feature
        """
        df_encoded = features.copy()
        
        # ============================================================
        # 1. ì¹´í…Œê³ ë¦¬ ì»¬ëŸ¼ ì¸ì½”ë”© (LabelEncoder)
        # ============================================================
        for col in self.categorical_cols:
            if col in df_encoded.columns:
                if fit:
                    self.label_encoders[col] = LabelEncoder()
                    df_encoded[col] = self.label_encoders[col].fit_transform(
                        df_encoded[col].astype(str)
                    )
                else:
                    le = self.label_encoders.get(col)
                    if le:
                        # í•™ìŠµ ì‹œ ì—†ë˜ ì¹´í…Œê³ ë¦¬ëŠ” ì²« ë²ˆì§¸ í´ë˜ìŠ¤ë¡œ ëŒ€ì²´
                        df_encoded[col] = df_encoded[col].astype(str).apply(
                            lambda x: le.transform([x])[0] if x in le.classes_ 
                            else 0  # Unknown â†’ 0
                        )
        
        # ============================================================
        # 2. Feature ì»¬ëŸ¼ ì„ íƒ
        # ============================================================
        feature_cols = self.categorical_cols + self.numerical_cols
        feature_cols = [col for col in feature_cols if col in df_encoded.columns]
        self.feature_cols = feature_cols
        
        X = df_encoded[feature_cols].values
        
        # ============================================================
        # 3. ìˆ˜ì¹˜í˜• ì •ê·œí™” (StandardScaler)
        # ============================================================
        if fit:
            X = self.scaler.fit_transform(X)
        else:
            X = self.scaler.transform(X)
        
        return X
    
    
    def process(self):
        """
        GCP ë°ì´í„°ë¡œ ML ëª¨ë¸ í•™ìŠµ
        
        Returns:
            self (ë©”ì„œë“œ ì²´ì´ë‹)
        """
        self.print_step("ML ëª¨ë¸ í•™ìŠµ (GCP ë°ì´í„°)")
        
        # ============================================================
        # 1. GCP ë°ì´í„° ì •ì œ
        # ============================================================
        print(f"\n   1ï¸âƒ£  GCP ë°ì´í„° ì •ì œ ì¤‘...")
        
        # ìˆ«ìí˜• ë³€í™˜
        self.df_gcp['AvgCPUUsage'] = pd.to_numeric(
            self.df_gcp['AvgCPUUsage'], errors='coerce'
        )
        self.df_gcp['AvgMemoryUsage'] = pd.to_numeric(
            self.df_gcp['AvgMemoryUsage'], errors='coerce'
        )
        
        # ê²°ì¸¡ì¹˜ ë° ì´ìƒì¹˜ ì œê±°
        df_clean = self.df_gcp.dropna(subset=['AvgCPUUsage', 'AvgMemoryUsage'])
        df_clean = df_clean[
            (df_clean['AvgCPUUsage'] > 0) & 
            (df_clean['AvgCPUUsage'] <= 1) &
            (df_clean['AvgMemoryUsage'] > 0) & 
            (df_clean['AvgMemoryUsage'] <= 1)
        ]
        
        print(f"      â€¢ ì›ë³¸: {len(self.df_gcp):,}ê±´")
        print(f"      â€¢ ì •ì œ í›„: {len(df_clean):,}ê±´")
        
        if len(df_clean) < 100:
            self.print_error("í•™ìŠµ ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤ (ìµœì†Œ 100ê±´ í•„ìš”)")
            return self
        
        # ============================================================
        # 2. Feature ì¶”ì¶œ ë° ì¸ì½”ë”©
        # ============================================================
        print(f"\n   2ï¸âƒ£  Feature ì¶”ì¶œ ì¤‘...")
        
        features = self._extract_features(df_clean)
        X = self._encode_features(features, fit=True)
        
        y_cpu = df_clean['AvgCPUUsage'].values
        y_memory = df_clean['AvgMemoryUsage'].values
        
        print(f"      â€¢ Feature ìˆ˜: {len(self.feature_cols)}")
        print(f"      â€¢ Feature ëª©ë¡: {self.feature_cols}")
        
        # ============================================================
        # 3. Train/Test ë¶„í• 
        # ============================================================
        print(f"\n   3ï¸âƒ£  Train/Test ë¶„í•  ì¤‘...")
        
        X_train, X_test, y_cpu_train, y_cpu_test = train_test_split(
            X, y_cpu, test_size=0.2, random_state=42
        )
        _, _, y_mem_train, y_mem_test = train_test_split(
            X, y_memory, test_size=0.2, random_state=42
        )
        
        print(f"      â€¢ Train: {len(X_train):,}ê±´")
        print(f"      â€¢ Test: {len(X_test):,}ê±´")
        
        # ============================================================
        # 4. CPU ëª¨ë¸ í•™ìŠµ
        # ============================================================
        print(f"\n   4ï¸âƒ£  CPU ëª¨ë¸ í•™ìŠµ ì¤‘...")
        
        self.cpu_model = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            min_samples_split=10,
            min_samples_leaf=5,
            random_state=42,
            n_jobs=-1
        )
        self.cpu_model.fit(X_train, y_cpu_train)
        
        # CPU ëª¨ë¸ í‰ê°€
        y_cpu_pred = self.cpu_model.predict(X_test)
        cpu_mae = mean_absolute_error(y_cpu_test, y_cpu_pred)
        cpu_r2 = r2_score(y_cpu_test, y_cpu_pred)
        
        print(f"      âœ… CPU MAE: {cpu_mae*100:.2f}%")
        print(f"      âœ… CPU RÂ²: {cpu_r2:.4f}")
        
        # ============================================================
        # 5. Memory ëª¨ë¸ í•™ìŠµ
        # ============================================================
        print(f"\n   5ï¸âƒ£  Memory ëª¨ë¸ í•™ìŠµ ì¤‘...")
        
        self.memory_model = RandomForestRegressor(
            n_estimators=100,
            max_depth=10,
            min_samples_split=10,
            min_samples_leaf=5,
            random_state=42,
            n_jobs=-1
        )
        self.memory_model.fit(X_train, y_mem_train)
        
        # Memory ëª¨ë¸ í‰ê°€
        y_mem_pred = self.memory_model.predict(X_test)
        mem_mae = mean_absolute_error(y_mem_test, y_mem_pred)
        mem_r2 = r2_score(y_mem_test, y_mem_pred)
        
        print(f"      âœ… Memory MAE: {mem_mae*100:.2f}%")
        print(f"      âœ… Memory RÂ²: {mem_r2:.4f}")
        
        # ============================================================
        # 6. Feature ì¤‘ìš”ë„ ì¶œë ¥
        # ============================================================
        print(f"\n   ğŸ“Š Feature ì¤‘ìš”ë„ (CPU):")
        importances = self.cpu_model.feature_importances_
        for i, col in enumerate(self.feature_cols):
            print(f"      â€¢ {col}: {importances[i]*100:.1f}%")
        
        # ============================================================
        # 7. ëª¨ë¸ ì €ì¥
        # ============================================================
        self._save_models()
        
        # í•™ìŠµ ê²°ê³¼ ì €ì¥
        self.training_results = {
            'cpu_mae': float(cpu_mae),
            'cpu_r2': float(cpu_r2),
            'memory_mae': float(mem_mae),
            'memory_r2': float(mem_r2),
            'train_samples': len(X_train),
            'test_samples': len(X_test),
            'feature_importance': {col: float(imp) for col, imp in zip(self.feature_cols, importances)}
        }
        
        return self
    
    
    def _save_models(self):
        """í•™ìŠµëœ ëª¨ë¸ ì €ì¥"""
        self.model_output_dir.mkdir(parents=True, exist_ok=True)
        
        joblib.dump(self.cpu_model, self.model_output_dir / 'cpu_model_v2.joblib')
        joblib.dump(self.memory_model, self.model_output_dir / 'memory_model_v2.joblib')
        joblib.dump(self.label_encoders, self.model_output_dir / 'label_encoders_v2.joblib')
        joblib.dump(self.scaler, self.model_output_dir / 'scaler_v2.joblib')
        joblib.dump(self.feature_cols, self.model_output_dir / 'feature_cols_v2.joblib')
        
        print(f"\n   ğŸ’¾ ëª¨ë¸ ì €ì¥: {self.model_output_dir}")
    
    
    def predict_aws(self):
        """
        AWS ë°ì´í„°ì— ëŒ€í•´ ì‚¬ìš©ë¥  ì˜ˆì¸¡
        
        Returns:
            self (ë©”ì„œë“œ ì²´ì´ë‹)
        """
        self.print_step("AWS ë°ì´í„° ì˜ˆì¸¡")
        
        if self.cpu_model is None:
            self.print_error("ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµí•˜ì„¸ìš” (process)")
            return self
        
        if len(self.df_aws) == 0:
            self.print_warning("AWS ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
            return self
        
        print(f"   ğŸ“Š AWS ë°ì´í„°: {len(self.df_aws):,}ê±´")
        
        # ============================================================
        # 1. Feature ì¶”ì¶œ
        # ============================================================
        print(f"\n   ğŸ”§ Feature ì¶”ì¶œ ì¤‘...")
        features = self._extract_features(self.df_aws)
        print(f"   âœ… Feature ì¶”ì¶œ ì™„ë£Œ: {len(features):,}ê±´, {len(self.feature_cols)}ê°œ ì»¬ëŸ¼")
        
        # ============================================================
        # 2. Feature ì¸ì½”ë”© (í•™ìŠµëœ ì¸ì½”ë” ì‚¬ìš©)
        # ============================================================
        X = self._encode_features(features, fit=False)
        
        # ============================================================
        # 3. ì˜ˆì¸¡
        # ============================================================
        print(f"\n   ğŸ”® ì˜ˆì¸¡ ì¤‘...")
        cpu_predictions = self.cpu_model.predict(X)
        memory_predictions = self.memory_model.predict(X)
        
        # ============================================================
        # 4. ê²°ê³¼ ì €ì¥
        # ============================================================
        self.df_predictions = self.df_aws.copy()
        self.df_predictions['PredictedCPU'] = cpu_predictions
        self.df_predictions['PredictedMemory'] = memory_predictions
        
        # ============================================================
        # 5. ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ íŒì •
        # ============================================================
        self.df_predictions['IsOverProvisioned'] = (
            (self.df_predictions['PredictedCPU'] < self.cpu_threshold) |
            (self.df_predictions['PredictedMemory'] < self.memory_threshold)
        )
        
        # ë‚­ë¹„ìœ¨ ê³„ì‚°
        self.df_predictions['CPUWastePercent'] = (
            (1 - self.df_predictions['PredictedCPU']) * 100
        )
        self.df_predictions['MemoryWastePercent'] = (
            (1 - self.df_predictions['PredictedMemory']) * 100
        )
        
        # ì˜ˆìƒ ì ˆê°ì•¡ (ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ì¸ ê²½ìš° 60% ì ˆê° ê°€ì •)
        if 'TotalHourlyCost' in self.df_predictions.columns:
            self.df_predictions['TotalHourlyCost'] = pd.to_numeric(
                self.df_predictions['TotalHourlyCost'], errors='coerce'
            ).fillna(0)
            
            self.df_predictions['PotentialSavings'] = np.where(
                self.df_predictions['IsOverProvisioned'],
                self.df_predictions['TotalHourlyCost'] * 0.6,
                0
            )
        
        # ============================================================
        # 6. ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        # ============================================================
        self._print_prediction_summary()
        
        return self
    
    
    def _print_prediction_summary(self):
        """ì˜ˆì¸¡ ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""
        print(f"\n{'='*100}")
        print("ğŸ“Š AWS ì‚¬ìš©ë¥  ì˜ˆì¸¡ ê²°ê³¼ (ML ê¸°ë°˜)")
        print(f"{'='*100}")
        
        total = len(self.df_predictions)
        over_prov = self.df_predictions['IsOverProvisioned'].sum()
        over_prov_rate = over_prov / total * 100 if total > 0 else 0
        
        print(f"\n   ğŸš¨ ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ íƒì§€:")
        print(f"      â€¢ ì „ì²´: {total:,}ê±´")
        print(f"      â€¢ ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹: {over_prov:,}ê±´ ({over_prov_rate:.1f}%)")
        print(f"      â€¢ ì •ìƒ: {total - over_prov:,}ê±´")
        
        # ì˜ˆì¸¡ê°’ ë¶„í¬
        print(f"\n   ğŸ“Š ì˜ˆì¸¡ ì‚¬ìš©ë¥  ë¶„í¬:")
        print(f"      â€¢ CPU í‰ê· : {self.df_predictions['PredictedCPU'].mean()*100:.1f}%")
        print(f"      â€¢ CPU ì¤‘ì•™ê°’: {self.df_predictions['PredictedCPU'].median()*100:.1f}%")
        print(f"      â€¢ CPU ìµœì†Œ: {self.df_predictions['PredictedCPU'].min()*100:.1f}%")
        print(f"      â€¢ CPU ìµœëŒ€: {self.df_predictions['PredictedCPU'].max()*100:.1f}%")
        print(f"      â€¢ Memory í‰ê· : {self.df_predictions['PredictedMemory'].mean()*100:.1f}%")
        print(f"      â€¢ Memory ì¤‘ì•™ê°’: {self.df_predictions['PredictedMemory'].median()*100:.1f}%")
        
        # ì„ê³„ê°’ ì´í•˜ ë¹„ìœ¨
        below_cpu = (self.df_predictions['PredictedCPU'] < self.cpu_threshold).sum()
        below_mem = (self.df_predictions['PredictedMemory'] < self.memory_threshold).sum()
        
        print(f"\n   ğŸ“‰ ì„ê³„ê°’({self.cpu_threshold*100:.0f}%) ì´í•˜:")
        print(f"      â€¢ CPU < {self.cpu_threshold*100:.0f}%: {below_cpu:,}ê±´ ({below_cpu/total*100:.1f}%)")
        print(f"      â€¢ Memory < {self.memory_threshold*100:.0f}%: {below_mem:,}ê±´ ({below_mem/total*100:.1f}%)")
        
        # ì˜ˆìƒ ì ˆê°ì•¡
        if 'PotentialSavings' in self.df_predictions.columns:
            total_savings = self.df_predictions['PotentialSavings'].sum()
            print(f"\n   ğŸ’° ì˜ˆìƒ ì ˆê°ì•¡:")
            print(f"      â€¢ ì´ ì ˆê° ê°€ëŠ¥: ${total_savings:,.2f}")
            print(f"      â€¢ ì—°ê°„ ì¶”ì •: ${total_savings * 12:,.2f}")
        
        print(f"\n{'='*100}")
    
    
    def save(self):
        """
        ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥
        
        Returns:
            self (ë©”ì„œë“œ ì²´ì´ë‹)
        """
        if self.df_predictions is None:
            self.print_warning("ì €ì¥í•  ì˜ˆì¸¡ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤")
            return self
        
        self.print_step("ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥", f"{self.result_output_path}")
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.result_output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # CSV ì €ì¥
        self.df_predictions.to_csv(self.result_output_path, index=False)
        
        self.print_success("ì €ì¥ ì™„ë£Œ")
        print(f"   ğŸ“‚ ê²½ë¡œ: {self.result_output_path}")
        print(f"   ğŸ“Š ë ˆì½”ë“œ: {len(self.df_predictions):,}ê±´")
        
        # ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ë§Œ ë³„ë„ ì €ì¥
        over_prov_path = self.result_output_path.parent / 'ml_overprovisioned_v2.csv'
        df_over = self.df_predictions[self.df_predictions['IsOverProvisioned']]
        
        if len(df_over) > 0:
            df_over.to_csv(over_prov_path, index=False)
            print(f"   ğŸ“‚ ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹: {over_prov_path}")
            print(f"   ğŸ“Š ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹: {len(df_over):,}ê±´")
        
        return self
    
    
    def run(self):
        """
        ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰: ë¡œë“œ â†’ í•™ìŠµ â†’ ì˜ˆì¸¡ â†’ ì €ì¥
        
        Returns:
            self (ë©”ì„œë“œ ì²´ì´ë‹)
        """
        return (self.load()
                .process()
                .predict_aws()
                .save())
    
    
    def get_results(self):
        """
        ê²°ê³¼ ë°˜í™˜
        
        Returns:
            tuple: (ì˜ˆì¸¡ ê²°ê³¼ DataFrame, í•™ìŠµ ê²°ê³¼ dict)
        """
        return (self.df_predictions, getattr(self, 'training_results', None))
    
    
    def get_overprovisioned(self):
        """
        ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ ë°ì´í„°ë§Œ ë°˜í™˜
        
        Returns:
            DataFrame: ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ ë°ì´í„°
        """
        if self.df_predictions is None:
            return None
        
        return self.df_predictions[self.df_predictions['IsOverProvisioned']].copy()


# ============================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================
if __name__ == "__main__":
    
    print("\n" + "="*100)
    print("ğŸš€ ML ê¸°ë°˜ ì‚¬ìš©ë¥  ì˜ˆì¸¡ v2 (resource_grouped.csv ì‚¬ìš©)")
    print("="*100)
    
    predictor = MLUsagePredictorV2('config/focus_config.yaml')
    predictor.run()
    
    # ê²°ê³¼ ì¡°íšŒ
    df_predictions, training_results = predictor.get_results()
    
    print(f"\nâœ… ì™„ë£Œ!")
    if df_predictions is not None:
        print(f"   ì „ì²´ ì˜ˆì¸¡: {len(df_predictions):,}ê±´")
        
        df_over = predictor.get_overprovisioned()
        if df_over is not None:
            print(f"   ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹: {len(df_over):,}ê±´")
    
    if training_results:
        print(f"\nğŸ“Š í•™ìŠµ ê²°ê³¼:")
        print(f"   CPU MAE: {training_results['cpu_mae']*100:.2f}%")
        print(f"   CPU RÂ²: {training_results['cpu_r2']:.4f}")
        print(f"   Memory MAE: {training_results['memory_mae']*100:.2f}%")
        print(f"   Memory RÂ²: {training_results['memory_r2']:.4f}")