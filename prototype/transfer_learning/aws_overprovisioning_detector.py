# -*- coding: utf-8 -*-
"""
AWS ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ íƒì§€ê¸° (Transfer Learning ê¸°ë°˜)

GCPì—ì„œ í•™ìŠµí•œ ì‚¬ìš©ë¥  íŒ¨í„´ì„ AWSì— ì ìš©í•˜ì—¬
ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ ë¦¬ì†ŒìŠ¤ë¥¼ íƒì§€í•©ë‹ˆë‹¤.
"""

import pandas as pd
import numpy as np
import yaml
from pathlib import Path
import sys

project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / 'data_processing'))

from pipeline_base import PipelineBase
from usage_estimator import UsageEstimator


class AWSOverprovisioningDetector(PipelineBase):
    """
    AWS ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ íƒì§€ í´ë˜ìŠ¤ (Transfer Learning ê¸°ë°˜)
    
    ì£¼ìš” ê¸°ëŠ¥:
    1. AWS FOCUS ë°ì´í„° ë¡œë“œ
    2. UsageEstimatorë¡œ CPU/Memory ì‚¬ìš©ë¥  ì¶”ì •
    3. ì¶”ì •ëœ ì‚¬ìš©ë¥  ê¸°ë°˜ ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ íƒì§€
    4. ë‚­ë¹„ ë¹„ìš© ê³„ì‚°
    """
    
    def __init__(self, config_path='config/focus_config.yaml'):
        """
        ì´ˆê¸°í™”
        
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        super().__init__(config_path)
        
        # ê²½ë¡œ ì„¤ì •
        data_config = self.config['data']
        self.aws_data_path = Path(data_config['aws_focus_output'])
        self.output_path = Path('results/transfer_learning/aws_overprovisioned.csv')
        
        # ì„ê³„ê°’
        thresholds = self.config['thresholds']['over_provisioning']
        self.cpu_threshold = thresholds['cpu_threshold']
        self.memory_threshold = thresholds['memory_threshold']
        
        # ë°ì´í„°
        self.df_aws = None
        self.df_estimated = None
        self.df_overprovisioned = None
        
        # UsageEstimator
        self.estimator = None
    
    
    def load(self):
        """
        AWS FOCUS ë°ì´í„° ë¡œë“œ
        
        Returns:
            self
        """
        self.print_step("AWS ë°ì´í„° ë¡œë”©", f"{self.aws_data_path}")
        
        if not self.aws_data_path.exists():
            self.print_error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.aws_data_path}")
            raise FileNotFoundError(f"{self.aws_data_path}")
        
        # CSV ë¡œë“œ
        self.df_aws = pd.read_csv(self.aws_data_path)
        
        self.print_success("ë¡œë“œ ì™„ë£Œ")
        print(f"   ğŸ“Š ë ˆì½”ë“œ: {len(self.df_aws):,}ê±´")
        print(f"   ğŸ“‹ ì»¬ëŸ¼: {len(self.df_aws.columns)}ê°œ")
        
        # ì„œë¹„ìŠ¤ í˜„í™©
        if 'ServiceName' in self.df_aws.columns:
            unique_services = self.df_aws['ServiceName'].nunique()
            print(f"   ğŸ”§ ê³ ìœ  ì„œë¹„ìŠ¤: {unique_services}ê°œ")
        
        return self
    
    
    def _init_estimator(self):
        """
        UsageEstimator ì´ˆê¸°í™”
        
        Returns:
            self
        """
        print("\nğŸ”§ UsageEstimator ì´ˆê¸°í™” ì¤‘...")
        
        self.estimator = UsageEstimator(self.config_path)
        self.estimator.run()
        
        self.print_success("UsageEstimator ì¤€ë¹„ ì™„ë£Œ")
        
        return self
    
    
    def estimate_usage(self):
        """
        AWS ì„œë¹„ìŠ¤ë³„ CPU/Memory ì‚¬ìš©ë¥  ì¶”ì •
        
        Returns:
            self
        """
        self.print_step("ì‚¬ìš©ë¥  ì¶”ì • (Transfer Learning)")
        
        if self.estimator is None:
            self._init_estimator()
        
        # ê³ ìœ  ì„œë¹„ìŠ¤ ëª©ë¡
        services = self.df_aws['ServiceName'].unique().tolist()
        print(f"   ğŸ“Š ì¶”ì • ëŒ€ìƒ: {len(services)}ê°œ ì„œë¹„ìŠ¤")
        
        # ì¼ê´„ ì¶”ì •
        df_service_estimation = self.estimator.estimate_batch(services)
        
        # AWS ë°ì´í„°ì— ì¶”ì •ê°’ ë³‘í•©
        self.df_estimated = self.df_aws.merge(
            df_service_estimation,
            left_on='ServiceName',
            right_on='aws_service',
            how='left'
        )
        
        self.print_success("ì‚¬ìš©ë¥  ì¶”ì • ì™„ë£Œ")
        print(f"   ğŸ“Š ì¶”ì •ëœ ë ˆì½”ë“œ: {len(self.df_estimated):,}ê±´")
        
        # ì¶”ì • í†µê³„
        if 'cpu_mean' in self.df_estimated.columns:
            avg_cpu = self.df_estimated['cpu_mean'].mean()
            avg_mem = self.df_estimated['memory_mean'].mean()
            avg_conf = self.df_estimated['confidence'].mean()
            
            print(f"\n   ğŸ“ˆ ì¶”ì • í†µê³„:")
            print(f"      â€¢ í‰ê·  CPU ì‚¬ìš©ë¥ : {avg_cpu*100:.1f}%")
            print(f"      â€¢ í‰ê·  Memory ì‚¬ìš©ë¥ : {avg_mem*100:.1f}%")
            print(f"      â€¢ í‰ê·  ì‹ ë¢°ë„: {avg_conf:.2f}")
        
        return self
    
    
    def process(self):
        """
        ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ íƒì§€
        
        ì¡°ê±´:
        - ì¶”ì • CPU ì‚¬ìš©ë¥  < cpu_threshold (30%)
        - ë˜ëŠ” ì¶”ì • Memory ì‚¬ìš©ë¥  < memory_threshold (30%)
        
        Returns:
            self
        """
        self.print_step("ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ íƒì§€")
        
        if self.df_estimated is None:
            self.estimate_usage()
        
        print(f"\nğŸ“Œ íƒì§€ ì¡°ê±´:")
        print(f"   â€¢ CPU ì„ê³„ê°’: {self.cpu_threshold*100:.0f}% ì´í•˜")
        print(f"   â€¢ Memory ì„ê³„ê°’: {self.memory_threshold*100:.0f}% ì´í•˜")
        
        # CPU/Memory ì»¬ëŸ¼ í™•ì¸
        if 'cpu_mean' not in self.df_estimated.columns:
            self.print_error("CPU ì¶”ì •ê°’ì´ ì—†ìŠµë‹ˆë‹¤.")
            return self
        
        # ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ í•„í„°ë§
        mask_cpu = self.df_estimated['cpu_mean'] < self.cpu_threshold
        mask_memory = self.df_estimated['memory_mean'] < self.memory_threshold
        
        self.df_overprovisioned = self.df_estimated[mask_cpu | mask_memory].copy()
        
        # ë‚­ë¹„ìœ¨ ê³„ì‚°
        self.df_overprovisioned['CPUWastePercent'] = (
            (1 - self.df_overprovisioned['cpu_mean']) * 100
        )
        self.df_overprovisioned['MemoryWastePercent'] = (
            (1 - self.df_overprovisioned['memory_mean']) * 100
        )
        
        # ì˜ˆìƒ ì ˆê°ì•¡ ê³„ì‚° (ë¹„ìš©ì˜ 60% ì ˆê° ê°€ëŠ¥ ê°€ì •)
        if 'BilledCost' in self.df_overprovisioned.columns:
            self.df_overprovisioned['PotentialSavings'] = (
                self.df_overprovisioned['BilledCost'] * 0.6
            )
        elif 'EffectiveCost' in self.df_overprovisioned.columns:
            self.df_overprovisioned['PotentialSavings'] = (
                self.df_overprovisioned['EffectiveCost'] * 0.6
            )
        
        # ê²°ê³¼ í†µê³„
        self._print_detection_summary()
        
        self.result = self.df_overprovisioned
        
        return self
    
    
    def _print_detection_summary(self):
        """íƒì§€ ê²°ê³¼ ìš”ì•½"""
        print(f"\n{'='*100}")
        print("ğŸ“Š ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ íƒì§€ ê²°ê³¼ (Transfer Learning ê¸°ë°˜)")
        print(f"{'='*100}")
        
        total_records = len(self.df_estimated)
        overprovisioned_count = len(self.df_overprovisioned)
        detection_rate = overprovisioned_count / total_records * 100 if total_records > 0 else 0
        
        print(f"\n   ğŸš¨ íƒì§€ í˜„í™©:")
        print(f"      â€¢ ì „ì²´ ë ˆì½”ë“œ: {total_records:,}ê±´")
        print(f"      â€¢ ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹: {overprovisioned_count:,}ê±´ ({detection_rate:.1f}%)")
        
        # ë§¤ì¹­ ë°©ë²•ë³„
        if 'method' in self.df_overprovisioned.columns:
            print(f"\n   ğŸ“Œ ë§¤ì¹­ ë°©ë²•ë³„:")
            for method, count in self.df_overprovisioned['method'].value_counts().items():
                pct = count / overprovisioned_count * 100
                print(f"      â€¢ {method:20s}: {count:,}ê±´ ({pct:.1f}%)")
        
        # ì‹ ë¢°ë„ë³„
        if 'confidence' in self.df_overprovisioned.columns:
            high_conf = (self.df_overprovisioned['confidence'] >= 0.8).sum()
            medium_conf = ((self.df_overprovisioned['confidence'] >= 0.5) & 
                          (self.df_overprovisioned['confidence'] < 0.8)).sum()
            low_conf = (self.df_overprovisioned['confidence'] < 0.5).sum()
            
            print(f"\n   ğŸ“Œ ì‹ ë¢°ë„ë³„:")
            print(f"      â€¢ ë†’ìŒ (â‰¥80%): {high_conf:,}ê±´")
            print(f"      â€¢ ì¤‘ê°„ (50-80%): {medium_conf:,}ê±´")
            print(f"      â€¢ ë‚®ìŒ (<50%): {low_conf:,}ê±´")
        
        # ì˜ˆìƒ ì ˆê°ì•¡
        if 'PotentialSavings' in self.df_overprovisioned.columns:
            total_savings = self.df_overprovisioned['PotentialSavings'].sum()
            print(f"\n   ğŸ’° ì˜ˆìƒ ì ˆê°ì•¡:")
            print(f"      â€¢ ì´ ì ˆê° ê°€ëŠ¥: ${total_savings:,.2f}")
            print(f"      â€¢ ì›”ê°„ ì¶”ì •: ${total_savings:,.2f}")
            print(f"      â€¢ ì—°ê°„ ì¶”ì •: ${total_savings * 12:,.2f}")
        
        # ì„œë¹„ìŠ¤ë³„ Top 5
        if 'ServiceName' in self.df_overprovisioned.columns:
            print(f"\n   ğŸ“Š ì„œë¹„ìŠ¤ë³„ Top 5:")
            service_counts = self.df_overprovisioned['ServiceName'].value_counts().head(5)
            
            for i, (service, count) in enumerate(service_counts.items(), 1):
                pct = count / overprovisioned_count * 100
                print(f"      {i}. {service[:45]:45s}: {count:,}ê±´ ({pct:.1f}%)")
        
        # í‰ê·  ë‚­ë¹„ìœ¨
        if 'CPUWastePercent' in self.df_overprovisioned.columns:
            avg_cpu_waste = self.df_overprovisioned['CPUWastePercent'].mean()
            avg_mem_waste = self.df_overprovisioned['MemoryWastePercent'].mean()
            
            print(f"\n   ğŸ“‰ í‰ê·  ë‚­ë¹„ìœ¨:")
            print(f"      â€¢ CPU: {avg_cpu_waste:.1f}%")
            print(f"      â€¢ Memory: {avg_mem_waste:.1f}%")
        
        print(f"\n{'='*100}")
    
    
    def save(self):
        """
        íƒì§€ ê²°ê³¼ ì €ì¥
        
        Returns:
            self
        """
        if self.df_overprovisioned is None or len(self.df_overprovisioned) == 0:
            self.print_warning("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return self
        
        self.print_step("ê²°ê³¼ ì €ì¥", f"{self.output_path}")
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.ensure_dir(self.output_path.parent)
        
        # CSV ì €ì¥
        self.df_overprovisioned.to_csv(self.output_path, index=False)
        
        # íŒŒì¼ í¬ê¸°
        file_size_kb = self.output_path.stat().st_size / 1024
        
        self.print_success("ì €ì¥ ì™„ë£Œ")
        print(f"   ğŸ“‚ ê²½ë¡œ: {self.output_path}")
        print(f"   ğŸ’¾ í¬ê¸°: {file_size_kb:.1f} KB")
        print(f"   ğŸ“Š ë ˆì½”ë“œ: {len(self.df_overprovisioned):,}ê±´")
        
        return self
    
    
    def run(self):
        """
        ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
        
        Returns:
            self
        """
        return (self.load()
                .estimate_usage()
                .process()
                .save())
    
    
    def get_results(self):
        """
        íƒì§€ ê²°ê³¼ ë°˜í™˜
        
        Returns:
            tuple: (ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ DataFrame, ì „ì²´ ì¶”ì • DataFrame)
        """
        return (self.df_overprovisioned, self.df_estimated)
    
    
    def get_summary_stats(self):
        """
        ìš”ì•½ í†µê³„ ë°˜í™˜ (ë…¼ë¬¸ìš©)
        
        Returns:
            dict: ìš”ì•½ í†µê³„
        """
        if self.df_overprovisioned is None:
            return {}
        
        stats = {
            'total_records': len(self.df_estimated),
            'overprovisioned_count': len(self.df_overprovisioned),
            'detection_rate': len(self.df_overprovisioned) / len(self.df_estimated) * 100,
            'avg_cpu_usage': self.df_overprovisioned['cpu_mean'].mean() * 100,
            'avg_memory_usage': self.df_overprovisioned['memory_mean'].mean() * 100,
            'avg_cpu_waste': self.df_overprovisioned['CPUWastePercent'].mean(),
            'avg_memory_waste': self.df_overprovisioned['MemoryWastePercent'].mean(),
            'avg_confidence': self.df_overprovisioned['confidence'].mean(),
            'exact_match_count': (self.df_overprovisioned['method'] == 'exact_match').sum(),
            'global_avg_count': (self.df_overprovisioned['method'] == 'global_average').sum(),
        }
        
        if 'PotentialSavings' in self.df_overprovisioned.columns:
            stats['total_potential_savings'] = self.df_overprovisioned['PotentialSavings'].sum()
        
        return stats


# ==================== ë©”ì¸ ì‹¤í–‰ ====================
if __name__ == "__main__":
    
    print("\nğŸš€ AWS ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ íƒì§€ (Transfer Learning ê¸°ë°˜)")
    print("="*100)
    
    detector = AWSOverprovisioningDetector('config/focus_config.yaml')
    detector.run()
    
    # ê²°ê³¼ ì¡°íšŒ
    df_overprovisioned, df_estimated = detector.get_results()
    
    print(f"\nâœ… íƒì§€ ì™„ë£Œ!")
    print(f"   ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹: {len(df_overprovisioned):,}ê±´")
    
    # ìš”ì•½ í†µê³„
    stats = detector.get_summary_stats()
    print(f"\nğŸ“Š ìš”ì•½ í†µê³„:")
    for key, value in stats.items():
        if isinstance(value, float):
            print(f"   â€¢ {key}: {value:.2f}")
        else:
            print(f"   â€¢ {key}: {value}")