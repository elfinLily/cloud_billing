# -*- coding: utf-8 -*-
"""
í†µí•© ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ íƒì§€ê¸° (Unified Over-Provisioning Detector)

============================================================
í•µì‹¬ ë¡œì§:
============================================================
GCP: AvgCPUUsage/AvgMemoryUsage ì§ì ‘ ë¹„êµ (< 30% â†’ ê³¼ë‹¤)
AWS: ML Classifier ì˜ˆì¸¡ ë“±ê¸‰ ì‚¬ìš© (Low â†’ ê³¼ë‹¤)

============================================================
ì…ë ¥: resource_grouped.csv (ProviderNameìœ¼ë¡œ GCP/AWS êµ¬ë¶„)
ì¶œë ¥: unified_overprovisioned.csv
============================================================

Author: Lily
Date: 2025-01
Purpose: ì„ì‚¬ ë…¼ë¬¸ - LLM ê¸°ë°˜ í´ë¼ìš°ë“œ FinOps ìë™í™” ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¹„êµ
"""

import pandas as pd
import numpy as np
import yaml
import json
import joblib
from pathlib import Path
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

import sys

# ============================================================
# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
# ============================================================
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / 'data_processing'))

try:
    from pipeline_base import PipelineBase
except ImportError:
    # PipelineBase ì—†ì„ ê²½ìš° ê¸°ë³¸ êµ¬í˜„
    class PipelineBase:
        def __init__(self, config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                self.config = yaml.safe_load(f)
        
        def print_step(self, msg, detail=""):
            print(f"\n{'='*80}")
            print(f"ğŸ“Œ {msg}")
            if detail:
                print(f"   {detail}")
            print(f"{'='*80}")
        
        def print_success(self, msg):
            print(f"   âœ… {msg}")
        
        def print_warning(self, msg):
            print(f"   âš ï¸ {msg}")
        
        def print_error(self, msg):
            print(f"   âŒ {msg}")
        
        def ensure_dir(self, path):
            Path(path).mkdir(parents=True, exist_ok=True)


class UnifiedOverProvisioningDetector(PipelineBase):
    """
    í†µí•© ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ íƒì§€ê¸°
    
    ============================================================
    íƒì§€ ë°©ë²•:
    ============================================================
    
    [GCP] ì§ì ‘ ì„ê³„ê°’ ë¹„êµ
        - AvgCPUUsage < 30% â†’ CPU ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹
        - AvgMemoryUsage < 30% â†’ Memory ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹
        - ì •í™•ë„: 100% (ì‹¤ì œ ì‚¬ìš©ë¥  ë°ì´í„° ìˆìŒ)
    
    [AWS] ML Classification ê¸°ë°˜
        - Transfer Learningìœ¼ë¡œ í•™ìŠµëœ ëª¨ë¸ ì‚¬ìš©
        - PredictedCPUClass == 'Low' â†’ CPU ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹
        - PredictedMemoryClass == 'Low' â†’ Memory ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹
        - ì •í™•ë„: 97% (ML ëª¨ë¸)
    
    ============================================================
    ì¶œë ¥ ì»¬ëŸ¼:
    ============================================================
    - ResourceId: ë¦¬ì†ŒìŠ¤ ì‹ë³„ì
    - ProviderName: GCP / AWS
    - ServiceName: ì„œë¹„ìŠ¤ëª…
    - DetectionMethod: 'Direct' (GCP) / 'ML_Classification' (AWS)
    - CPUStatus: 'OverProvisioned' / 'Normal'
    - MemoryStatus: 'OverProvisioned' / 'Normal'
    - CPUValue: ì‹¤ì œê°’(GCP) / ì˜ˆì¸¡ë“±ê¸‰(AWS)
    - MemoryValue: ì‹¤ì œê°’(GCP) / ì˜ˆì¸¡ë“±ê¸‰(AWS)
    - TotalHourlyCost: ì‹œê°„ë‹¹ ë¹„ìš©
    - PotentialSavings: ì˜ˆìƒ ì ˆê°ì•¡
    """
    
    # ============================================================
    # ì„œë¹„ìŠ¤ â†’ UnifiedCategory ë§¤í•‘ (ML ì˜ˆì¸¡ìš©)
    # ============================================================
    SERVICE_CATEGORY_MAP = {
        # Compute
        'compute engine': 'Compute', 'ec2': 'Compute', 'amazon ec2': 'Compute',
        'cloud functions': 'Compute', 'lambda': 'Compute', 'aws lambda': 'Compute',
        'cloud run': 'Compute', 'ecs': 'Compute', 'fargate': 'Compute',
        'app engine': 'Compute', 'elastic beanstalk': 'Compute',
        
        # Container
        'kubernetes engine': 'Container', 'gke': 'Container',
        'eks': 'Container', 'amazon eks': 'Container',
        
        # Database
        'cloud sql': 'Database', 'rds': 'Database', 'amazon rds': 'Database',
        'aurora': 'Database', 'dynamodb': 'Database', 'bigtable': 'Database',
        'firestore': 'Database', 'elasticache': 'Database', 'redshift': 'Database',
        
        # Storage
        'cloud storage': 'Storage', 's3': 'Storage', 'amazon s3': 'Storage',
        'persistent disk': 'Storage', 'ebs': 'Storage', 'efs': 'Storage',
        
        # Analytics
        'bigquery': 'Analytics', 'athena': 'Analytics', 'dataproc': 'Analytics',
        'emr': 'Analytics', 'kinesis': 'Analytics', 'glue': 'Analytics',
        
        # AI/ML
        'vertex ai': 'AI_ML', 'sagemaker': 'AI_ML', 'automl': 'AI_ML',
        
        # Networking
        'vpc': 'Networking', 'cloud load balancing': 'Networking',
        'elb': 'Networking', 'cloudfront': 'Networking', 'cloud cdn': 'Networking',
        
        # Monitoring
        'cloud monitoring': 'Monitoring', 'cloudwatch': 'Monitoring',
        
        # Security
        'iam': 'Security', 'kms': 'Security', 'waf': 'Security',
        
        # Messaging
        'pub/sub': 'Messaging', 'sns': 'Messaging', 'sqs': 'Messaging',
    }
    
    
    def __init__(self, config_path='config/focus_config.yaml'):
        """
        ì´ˆê¸°í™”
        
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        super().__init__(config_path)
        
        # ============================================================
        # ê²½ë¡œ ì„¤ì • (config ê¸°ë°˜)
        # ============================================================
        data_config = self.config['data']
        self.input_path = Path(data_config['resource_grouped_output'])
        self.output_path = Path('results/transfer_learning/unified_overprovisioned.csv')
        
        # ML ëª¨ë¸ ê²½ë¡œ
        self.model_dir = Path('results/transfer_learning/models/classifier')
        
        # ============================================================
        # ì„ê³„ê°’ ì„¤ì • (config ê¸°ë°˜)
        # ============================================================
        thresholds = self.config['thresholds']['over_provisioning']
        self.cpu_threshold = thresholds['cpu_threshold']      # 0.30 (30%)
        self.memory_threshold = thresholds['memory_threshold']  # 0.30 (30%)
        
        # ============================================================
        # ë°ì´í„° & ëª¨ë¸
        # ============================================================
        self.df = None              # ì „ì²´ ë°ì´í„°
        self.df_gcp = None          # GCP ë°ì´í„°
        self.df_aws = None          # AWS ë°ì´í„°
        
        self.df_gcp_result = None   # GCP íƒì§€ ê²°ê³¼
        self.df_aws_result = None   # AWS íƒì§€ ê²°ê³¼
        self.df_unified = None      # í†µí•© ê²°ê³¼
        
        # ML ëª¨ë¸ (AWSìš©)
        self.cpu_model = None
        self.memory_model = None
        self.label_encoders = {}
        self.scaler = None
        self.class_encoder = None
        
        # í†µê³„
        self.stats = {
            'gcp': {'total': 0, 'over_provisioned': 0},
            'aws': {'total': 0, 'over_provisioned': 0}
        }
    
    
    def load(self):
        """
        ë°ì´í„° ë° ML ëª¨ë¸ ë¡œë“œ
        
        Returns:
            self
        """
        self.print_step("ë°ì´í„° ë¡œë“œ", f"{self.input_path}")
        
        # ============================================================
        # 1. resource_grouped.csv ë¡œë“œ
        # ============================================================
        if not self.input_path.exists():
            self.print_error(f"íŒŒì¼ ì—†ìŒ: {self.input_path}")
            raise FileNotFoundError(f"{self.input_path}")
        
        self.df = pd.read_csv(self.input_path)
        self.print_success(f"ë°ì´í„° ë¡œë“œ: {len(self.df):,}ê±´")
        
        # ============================================================
        # 2. GCP/AWS ë¶„ë¦¬
        # ============================================================
        self._separate_by_provider()
        
        # ============================================================
        # 3. ML ëª¨ë¸ ë¡œë“œ (AWS ì˜ˆì¸¡ìš©)
        # ============================================================
        if len(self.df_aws) > 0:
            self._load_ml_models()
        
        return self
    
    
    def _separate_by_provider(self):
        """
        ProviderNameìœ¼ë¡œ GCP/AWS ë°ì´í„° ë¶„ë¦¬
        """
        print(f"\n   ğŸ”„ í´ë¼ìš°ë“œ ì œê³µìë³„ ë¶„ë¦¬...")
        
        # ProviderName ì»¬ëŸ¼ í™•ì¸
        if 'ProviderName' not in self.df.columns:
            self.print_warning("ProviderName ì»¬ëŸ¼ ì—†ìŒ - ì „ì²´ë¥¼ GCPë¡œ ì²˜ë¦¬")
            self.df_gcp = self.df.copy()
            self.df_aws = pd.DataFrame()
            return
        
        # GCP í•„í„°
        gcp_keywords = ['GCP', 'Google', 'google']
        gcp_mask = self.df['ProviderName'].str.contains(
            '|'.join(gcp_keywords), case=False, na=False
        )
        self.df_gcp = self.df[gcp_mask].copy()
        
        # AWS í•„í„°
        aws_keywords = ['AWS', 'Amazon', 'amazon']
        aws_mask = self.df['ProviderName'].str.contains(
            '|'.join(aws_keywords), case=False, na=False
        )
        self.df_aws = self.df[aws_mask].copy()
        
        # í†µê³„ ì €ì¥
        self.stats['gcp']['total'] = len(self.df_gcp)
        self.stats['aws']['total'] = len(self.df_aws)
        
        print(f"   âœ… GCP: {len(self.df_gcp):,}ê±´")
        print(f"   âœ… AWS: {len(self.df_aws):,}ê±´")
        
        # ê¸°íƒ€ ë°ì´í„° ê²½ê³ 
        other_count = len(self.df) - len(self.df_gcp) - len(self.df_aws)
        if other_count > 0:
            self.print_warning(f"ê¸°íƒ€ Provider: {other_count:,}ê±´ (ì œì™¸ë¨)")
    
    
    def _load_ml_models(self):
        """
        AWS ì˜ˆì¸¡ìš© ML ëª¨ë¸ ë¡œë“œ
        """
        print(f"\n   ğŸ”„ ML ëª¨ë¸ ë¡œë“œ...")
        
        # ëª¨ë¸ íŒŒì¼ í™•ì¸
        cpu_model_path = self.model_dir / 'cpu_classifier.joblib'
        memory_model_path = self.model_dir / 'memory_classifier.joblib'
        
        if not cpu_model_path.exists():
            self.print_error(f"CPU ëª¨ë¸ ì—†ìŒ: {cpu_model_path}")
            self.print_warning("ML ëª¨ë¸ ì—†ìŒ - AWS ë°ì´í„°ëŠ” ì²˜ë¦¬ ë¶ˆê°€")
            self.print_warning("ë¨¼ì € ml_usage_classifier.py ì‹¤í–‰ í•„ìš”")
            return
        
        # ëª¨ë¸ ë¡œë“œ
        self.cpu_model = joblib.load(cpu_model_path)
        self.memory_model = joblib.load(memory_model_path)
        self.label_encoders = joblib.load(self.model_dir / 'label_encoders.joblib')
        self.scaler = joblib.load(self.model_dir / 'scaler.joblib')
        self.class_encoder = joblib.load(self.model_dir / 'class_encoder.joblib')
        
        self.print_success("ML ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        print(f"      â€¢ CPU Classifier: âœ…")
        print(f"      â€¢ Memory Classifier: âœ…")
        print(f"      â€¢ Label Encoders: âœ…")
        print(f"      â€¢ Scaler: âœ…")
    
    
    def process(self):
        """
        ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ íƒì§€ ì‹¤í–‰
        
        Returns:
            self
        """
        self.print_step("ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ íƒì§€")
        
        results = []
        
        # ============================================================
        # 1. GCP ì§ì ‘ íƒì§€
        # ============================================================
        if len(self.df_gcp) > 0:
            self.df_gcp_result = self._detect_gcp()
            if len(self.df_gcp_result) > 0:
                results.append(self.df_gcp_result)
        
        # ============================================================
        # 2. AWS ML ê¸°ë°˜ íƒì§€
        # ============================================================
        if len(self.df_aws) > 0 and self.cpu_model is not None:
            self.df_aws_result = self._detect_aws()
            if len(self.df_aws_result) > 0:
                results.append(self.df_aws_result)
        elif len(self.df_aws) > 0:
            self.print_warning("AWS ë°ì´í„° ìˆìœ¼ë‚˜ ML ëª¨ë¸ ì—†ìŒ - ìŠ¤í‚µ")
        
        # ============================================================
        # 3. ê²°ê³¼ í†µí•©
        # ============================================================
        if results:
            self.df_unified = pd.concat(results, ignore_index=True)
        else:
            self.df_unified = pd.DataFrame()
        
        # í†µê³„ ì¶œë ¥
        self._print_summary()
        
        return self
    
    
    def _detect_gcp(self):
        """
        GCP ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ íƒì§€ (ì§ì ‘ ì„ê³„ê°’ ë¹„êµ)
        
        ì¡°ê±´:
        - AvgCPUUsage < 30% â†’ CPU ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹
        - AvgMemoryUsage < 30% â†’ Memory ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹
        
        Returns:
            DataFrame: íƒì§€ëœ ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ ë¦¬ì†ŒìŠ¤
        """
        print(f"\n   ğŸ” [GCP] ì§ì ‘ ì„ê³„ê°’ ë¹„êµ...")
        print(f"      â€¢ CPU ì„ê³„ê°’: < {self.cpu_threshold*100:.0f}%")
        print(f"      â€¢ Memory ì„ê³„ê°’: < {self.memory_threshold*100:.0f}%")
        
        df = self.df_gcp.copy()
        
        # ì‚¬ìš©ë¥  ì»¬ëŸ¼ í™•ì¸
        cpu_col = 'AvgCPUUsage'
        mem_col = 'AvgMemoryUsage'
        
        if cpu_col not in df.columns:
            self.print_warning(f"GCP ë°ì´í„°ì— {cpu_col} ì—†ìŒ")
            return pd.DataFrame()
        
        # ìˆ«ì ë³€í™˜
        df[cpu_col] = pd.to_numeric(df[cpu_col], errors='coerce').fillna(0)
        df[mem_col] = pd.to_numeric(df[mem_col], errors='coerce').fillna(0)
        
        # ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ íŒì •
        cpu_over = df[cpu_col] < self.cpu_threshold
        mem_over = df[mem_col] < self.memory_threshold
        is_over = cpu_over | mem_over
        
        df_over = df[is_over].copy()
        
        # ê²°ê³¼ ì»¬ëŸ¼ ì¶”ê°€
        df_over['DetectionMethod'] = 'Direct'
        df_over['CPUStatus'] = np.where(
            df_over[cpu_col] < self.cpu_threshold,
            'OverProvisioned', 'Normal'
        )
        df_over['MemoryStatus'] = np.where(
            df_over[mem_col] < self.memory_threshold,
            'OverProvisioned', 'Normal'
        )
        df_over['CPUValue'] = df_over[cpu_col].apply(lambda x: f"{x*100:.1f}%")
        df_over['MemoryValue'] = df_over[mem_col].apply(lambda x: f"{x*100:.1f}%")
        
        # ì˜ˆìƒ ì ˆê°ì•¡ ê³„ì‚° (ë‚­ë¹„ ë¹„ìœ¨ ê¸°ë°˜)
        cost_col = 'TotalHourlyCost'
        if cost_col in df_over.columns:
            df_over[cost_col] = pd.to_numeric(df_over[cost_col], errors='coerce').fillna(0)
            
            # ë‚­ë¹„ ë¹„ìœ¨ = 1 - ì‹¤ì œ ì‚¬ìš©ë¥ 
            cpu_waste = 1 - df_over[cpu_col]
            mem_waste = 1 - df_over[mem_col]
            avg_waste = (cpu_waste + mem_waste) / 2
            
            df_over['WasteRatio'] = avg_waste
            df_over['PotentialSavings'] = df_over[cost_col] * avg_waste
        else:
            df_over['WasteRatio'] = 0
            df_over['PotentialSavings'] = 0
        
        # í†µê³„ ì €ì¥
        self.stats['gcp']['over_provisioned'] = len(df_over)
        
        print(f"      âœ… íƒì§€: {len(df_over):,}ê±´ / {len(self.df_gcp):,}ê±´")
        print(f"         ({len(df_over)/len(self.df_gcp)*100:.1f}%)")
        
        return df_over
    
    
    def _detect_aws(self):
        """
        AWS ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ íƒì§€ (ML Classification ê¸°ë°˜)
        
        ì¡°ê±´:
        - PredictedCPUClass == 'Low' â†’ CPU ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹
        - PredictedMemoryClass == 'Low' â†’ Memory ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹
        
        Returns:
            DataFrame: íƒì§€ëœ ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ ë¦¬ì†ŒìŠ¤
        """
        print(f"\n   ğŸ” [AWS] ML Classification ê¸°ë°˜ íƒì§€...")
        print(f"      â€¢ ëª¨ë¸: RandomForestClassifier (97% Accuracy)")
        print(f"      â€¢ ê¸°ì¤€: 'Low' ë“±ê¸‰ â†’ ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹")
        
        df = self.df_aws.copy()
        
        # ============================================================
        # Feature ì¤€ë¹„
        # ============================================================
        df = self._prepare_features(df)
        
        # Feature ì¸ì½”ë”©
        X = self._encode_features(df)
        
        if X is None or len(X) == 0:
            self.print_warning("Feature ì¸ì½”ë”© ì‹¤íŒ¨")
            return pd.DataFrame()
        
        # ============================================================
        # ML ì˜ˆì¸¡
        # ============================================================
        print(f"      ğŸ”„ ML ì˜ˆì¸¡ ì¤‘...")
        
        cpu_pred_encoded = self.cpu_model.predict(X)
        mem_pred_encoded = self.memory_model.predict(X)
        
        # ì¸ì½”ë”© â†’ ë“±ê¸‰ ë³€í™˜
        cpu_pred = self.class_encoder.inverse_transform(cpu_pred_encoded)
        mem_pred = self.class_encoder.inverse_transform(mem_pred_encoded)
        
        df['PredictedCPUClass'] = cpu_pred
        df['PredictedMemoryClass'] = mem_pred
        
        # ë“±ê¸‰ ë¶„í¬ ì¶œë ¥
        print(f"\n      ğŸ“Š ì˜ˆì¸¡ ë“±ê¸‰ ë¶„í¬:")
        print(f"         CPU:")
        for cls in ['Low', 'Medium', 'High']:
            cnt = (cpu_pred == cls).sum()
            print(f"            â€¢ {cls}: {cnt:,}ê±´ ({cnt/len(df)*100:.1f}%)")
        print(f"         Memory:")
        for cls in ['Low', 'Medium', 'High']:
            cnt = (mem_pred == cls).sum()
            print(f"            â€¢ {cls}: {cnt:,}ê±´ ({cnt/len(df)*100:.1f}%)")
        
        # ============================================================
        # ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ íŒì • (Low ë“±ê¸‰)
        # ============================================================
        cpu_over = df['PredictedCPUClass'] == 'Low'
        mem_over = df['PredictedMemoryClass'] == 'Low'
        is_over = cpu_over | mem_over
        
        df_over = df[is_over].copy()
        
        # ê²°ê³¼ ì»¬ëŸ¼ ì¶”ê°€
        df_over['DetectionMethod'] = 'ML_Classification'
        df_over['CPUStatus'] = np.where(
            df_over['PredictedCPUClass'] == 'Low',
            'OverProvisioned', 'Normal'
        )
        df_over['MemoryStatus'] = np.where(
            df_over['PredictedMemoryClass'] == 'Low',
            'OverProvisioned', 'Normal'
        )
        df_over['CPUValue'] = df_over['PredictedCPUClass']
        df_over['MemoryValue'] = df_over['PredictedMemoryClass']
        
        # ì˜ˆìƒ ì ˆê°ì•¡ ê³„ì‚°
        cost_col = 'TotalHourlyCost'
        if cost_col in df_over.columns:
            df_over[cost_col] = pd.to_numeric(df_over[cost_col], errors='coerce').fillna(0)
            
            # Low ë“±ê¸‰ â†’ ì•½ 50% ì ˆê° ê°€ì •
            # (Low = í•˜ìœ„ 25% ì‚¬ìš©ë¥  â†’ í‰ê·  ~12.5% â†’ 87.5% ë‚­ë¹„)
            df_over['WasteRatio'] = 0.5  # ë³´ìˆ˜ì  ì¶”ì •
            df_over['PotentialSavings'] = df_over[cost_col] * 0.5
        else:
            df_over['WasteRatio'] = 0
            df_over['PotentialSavings'] = 0
        
        # í†µê³„ ì €ì¥
        self.stats['aws']['over_provisioned'] = len(df_over)
        
        print(f"\n      âœ… íƒì§€: {len(df_over):,}ê±´ / {len(self.df_aws):,}ê±´")
        print(f"         ({len(df_over)/len(self.df_aws)*100:.1f}%)")
        
        return df_over
    
    
    def _prepare_features(self, df):
        """
        AWS ë°ì´í„° Feature ì¤€ë¹„
        """
        # ServiceName â†’ UnifiedCategory
        if 'ServiceName' in df.columns:
            df['UnifiedCategory'] = df['ServiceName'].apply(self._map_to_category)
        else:
            df['UnifiedCategory'] = 'Other'
        
        # LogCost
        cost_col = 'TotalHourlyCost'
        if cost_col in df.columns:
            df['LogCost'] = np.log1p(
                pd.to_numeric(df[cost_col], errors='coerce').fillna(0)
            )
        else:
            df['LogCost'] = 0
        
        # HourOfDay, DayOfWeek
        if 'HourlyTimestamp' in df.columns:
            df['HourlyTimestamp'] = pd.to_datetime(df['HourlyTimestamp'], errors='coerce')
            df['HourOfDay'] = df['HourlyTimestamp'].dt.hour.fillna(12).astype(int)
            df['DayOfWeek'] = df['HourlyTimestamp'].dt.dayofweek.fillna(3).astype(int)
        else:
            df['HourOfDay'] = 12
            df['DayOfWeek'] = 3
        
        # ResourceType ê¸°ë³¸ê°’
        if 'ResourceType' not in df.columns:
            df['ResourceType'] = 'Unknown'
        
        return df
    
    
    def _map_to_category(self, service_name):
        """
        ì„œë¹„ìŠ¤ëª… â†’ UnifiedCategory ë§¤í•‘
        """
        if pd.isna(service_name):
            return 'Other'
        
        service_lower = str(service_name).lower()
        
        for keyword, category in self.SERVICE_CATEGORY_MAP.items():
            if keyword in service_lower:
                return category
        
        return 'Other'
    
    
    def _encode_features(self, df):
        """
        Feature ì¸ì½”ë”© (í•™ìŠµëœ ì¸ì½”ë” ì‚¬ìš©)
        """
        try:
            encoded_data = []
            
            # Categorical
            categorical_cols = ['UnifiedCategory', 'ResourceType']
            for col in categorical_cols:
                if col not in self.label_encoders:
                    continue
                
                encoder = self.label_encoders[col]
                known_classes = set(encoder.classes_)
                
                values = df[col].fillna('Unknown').astype(str)
                values = values.apply(lambda x: x if x in known_classes else 'Unknown')
                
                encoded = encoder.transform(values)
                encoded_data.append(encoded.reshape(-1, 1))
            
            # Numerical
            numerical_cols = ['LogCost', 'HourOfDay', 'DayOfWeek']
            numerical_data = df[numerical_cols].fillna(0).values
            numerical_scaled = self.scaler.transform(numerical_data)
            encoded_data.append(numerical_scaled)
            
            return np.hstack(encoded_data)
        
        except Exception as e:
            self.print_error(f"Feature ì¸ì½”ë”© ì‹¤íŒ¨: {e}")
            return None
    
    
    def _print_summary(self):
        """
        íƒì§€ ê²°ê³¼ ìš”ì•½ ì¶œë ¥
        """
        print(f"\n{'='*80}")
        print(f"ğŸ“Š ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ íƒì§€ ê²°ê³¼ ìš”ì•½")
        print(f"{'='*80}")
        
        # GCP í†µê³„
        gcp_total = self.stats['gcp']['total']
        gcp_over = self.stats['gcp']['over_provisioned']
        gcp_pct = (gcp_over / gcp_total * 100) if gcp_total > 0 else 0
        
        print(f"\n   [GCP] ì§ì ‘ íƒì§€ (ì„ê³„ê°’ < 30%)")
        print(f"      â€¢ ì „ì²´: {gcp_total:,}ê±´")
        print(f"      â€¢ ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹: {gcp_over:,}ê±´ ({gcp_pct:.1f}%)")
        
        # AWS í†µê³„
        aws_total = self.stats['aws']['total']
        aws_over = self.stats['aws']['over_provisioned']
        aws_pct = (aws_over / aws_total * 100) if aws_total > 0 else 0
        
        print(f"\n   [AWS] ML Classification (Low ë“±ê¸‰)")
        print(f"      â€¢ ì „ì²´: {aws_total:,}ê±´")
        print(f"      â€¢ ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹: {aws_over:,}ê±´ ({aws_pct:.1f}%)")
        
        # í†µí•© í†µê³„
        total = gcp_total + aws_total
        total_over = gcp_over + aws_over
        total_pct = (total_over / total * 100) if total > 0 else 0
        
        print(f"\n   [í†µí•©]")
        print(f"      â€¢ ì „ì²´: {total:,}ê±´")
        print(f"      â€¢ ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹: {total_over:,}ê±´ ({total_pct:.1f}%)")
        
        # ì˜ˆìƒ ì ˆê°ì•¡
        if self.df_unified is not None and 'PotentialSavings' in self.df_unified.columns:
            savings = self.df_unified['PotentialSavings'].sum()
            print(f"\n   ğŸ’° ì˜ˆìƒ ì ˆê°ì•¡:")
            print(f"      â€¢ ì‹œê°„ë‹¹: ${savings:,.2f}")
            print(f"      â€¢ ì›”ê°„: ${savings * 24 * 30:,.2f}")
            print(f"      â€¢ ì—°ê°„: ${savings * 24 * 365:,.2f}")
        
        print(f"\n{'='*80}")
    
    
    def save(self):
        """
        ê²°ê³¼ ì €ì¥
        
        Returns:
            self
        """
        self.print_step("ê²°ê³¼ ì €ì¥")
        
        if self.df_unified is None or len(self.df_unified) == 0:
            self.print_warning("ì €ì¥í•  ê²°ê³¼ ì—†ìŒ")
            return self
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.ensure_dir(self.output_path.parent)
        
        # ì¶œë ¥ ì»¬ëŸ¼ ì„ íƒ
        output_cols = [
            'ResourceId', 'ProviderName', 'ServiceName', 'ResourceType',
            'DetectionMethod', 'CPUStatus', 'MemoryStatus',
            'CPUValue', 'MemoryValue',
            'TotalHourlyCost', 'WasteRatio', 'PotentialSavings'
        ]
        
        # ì¡´ì¬í•˜ëŠ” ì»¬ëŸ¼ë§Œ ì„ íƒ
        available_cols = [col for col in output_cols if col in self.df_unified.columns]
        df_output = self.df_unified[available_cols]
        
        # CSV ì €ì¥
        df_output.to_csv(self.output_path, index=False, encoding='utf-8-sig')
        
        self.print_success(f"ì €ì¥ ì™„ë£Œ: {self.output_path}")
        print(f"      â€¢ ë ˆì½”ë“œ: {len(df_output):,}ê±´")
        
        # GCP/AWS ë³„ë„ ì €ì¥
        if self.df_gcp_result is not None and len(self.df_gcp_result) > 0:
            gcp_path = self.output_path.parent / 'gcp_overprovisioned.csv'
            self.df_gcp_result.to_csv(gcp_path, index=False, encoding='utf-8-sig')
            print(f"      â€¢ GCP: {gcp_path}")
        
        if self.df_aws_result is not None and len(self.df_aws_result) > 0:
            aws_path = self.output_path.parent / 'aws_overprovisioned.csv'
            self.df_aws_result.to_csv(aws_path, index=False, encoding='utf-8-sig')
            print(f"      â€¢ AWS: {aws_path}")
        
        # í†µê³„ JSON ì €ì¥
        stats_path = self.output_path.parent / 'detection_stats.json'
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(self.stats, f, indent=2, ensure_ascii=False)
        print(f"      â€¢ í†µê³„: {stats_path}")
        
        return self
    
    
    def run(self):
        """
        ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        
        Returns:
            self
        """
        return self.load().process().save()
    
    
    def get_results(self):
        """
        ê²°ê³¼ ë°˜í™˜
        
        Returns:
            tuple: (í†µí•© ê²°ê³¼ DataFrame, í†µê³„ ë”•ì…”ë„ˆë¦¬)
        """
        return (self.df_unified, self.stats)


# ============================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================
if __name__ == "__main__":
    
    print("\n" + "="*80)
    print("ğŸš€ í†µí•© ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ íƒì§€ê¸°")
    print("="*80)
    print("ğŸ“Œ íƒì§€ ë°©ë²•:")
    print("   â€¢ GCP: ì§ì ‘ ì„ê³„ê°’ ë¹„êµ (AvgCPU/Memory < 30%)")
    print("   â€¢ AWS: ML Classification (Low ë“±ê¸‰ = ê³¼ë‹¤)")
    print("="*80)
    
    detector = UnifiedOverProvisioningDetector('config/focus_config.yaml')
    detector.run()
    
    df_result, stats = detector.get_results()
    
    print(f"\nâœ… ì™„ë£Œ!")
    if df_result is not None:
        print(f"   ì´ ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹: {len(df_result):,}ê±´")