# -*- coding: utf-8 -*-
"""
ML ê¸°ë°˜ ì‚¬ìš©ë¥  ë¶„ë¥˜ ëª¨ë¸ (Classification)

============================================================
í•µì‹¬ ë³€ê²½: Regression â†’ Classification
============================================================
- ê¸°ì¡´: CPU ì‚¬ìš©ë¥  45.3% ì˜ˆì¸¡ (ì—°ì†ê°’) â†’ RÂ² 0.08ë¡œ ì‹¤íŒ¨
- ë³€ê²½: "Low/Medium/High" ë“±ê¸‰ ì˜ˆì¸¡ (ë²”ì£¼í˜•) â†’ Accuracy/F1 ì‚¬ìš©

============================================================
ë“±ê¸‰ ë¶„ë¥˜ ê¸°ì¤€ (Percentile ê¸°ë°˜):
============================================================
- Low: í•˜ìœ„ 25% (ì‚¬ìš©ë¥  < P25) â†’ ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ ê°€ëŠ¥ì„± ë†’ìŒ
- Medium: ì¤‘ê°„ 50% (P25 ~ P75) â†’ ì ì • ì‚¬ìš©
- High: ìƒìœ„ 25% (ì‚¬ìš©ë¥  > P75) â†’ íš¨ìœ¨ì  ì‚¬ìš©

============================================================
Author: Lily
Date: 2025-01
Purpose: ì„ì‚¬ ë…¼ë¬¸ - LLM ê¸°ë°˜ í´ë¼ìš°ë“œ FinOps ìë™í™” ì‹œìŠ¤í…œ ì„±ëŠ¥ ë¹„êµ
============================================================
"""

import pandas as pd
import numpy as np
import yaml
import json
from pathlib import Path
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier  # â† Regressor â†’ Classifier
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.metrics import (
    accuracy_score, 
    precision_score, 
    recall_score, 
    f1_score,
    classification_report,
    confusion_matrix
)
import joblib

import sys

# ============================================================
# í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì •
# ============================================================
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / 'data_processing'))

try:
    from pipeline_base import PipelineBase
except ImportError:
    class PipelineBase:
        def __init__(self, config_path):
            with open(config_path, 'r', encoding='utf-8') as f:
                self.config = yaml.safe_load(f)
        
        def print_step(self, msg, detail=""):
            print(f"\n{'='*60}")
            print(f"ğŸ“Œ {msg}")
            if detail:
                print(f"   {detail}")
            print(f"{'='*60}")
        
        def print_success(self, msg):
            print(f"   âœ… {msg}")
        
        def print_warning(self, msg):
            print(f"   âš ï¸ {msg}")
        
        def print_error(self, msg):
            print(f"   âŒ {msg}")
        
        def ensure_dir(self, path):
            Path(path).mkdir(parents=True, exist_ok=True)


class MLUsageClassifier(PipelineBase):
    """
    ML ê¸°ë°˜ ì‚¬ìš©ë¥  ë¶„ë¥˜ ëª¨ë¸
    
    ============================================================
    Regression vs Classification:
    ============================================================
    Regression (ê¸°ì¡´):
        - ëª©í‘œ: CPU = 0.453 ì˜ˆì¸¡
        - í‰ê°€: MAE, RÂ²
        - ë¬¸ì œ: RÂ² 0.08 â†’ ì˜ˆì¸¡ë ¥ ì—†ìŒ
    
    Classification (ë³€ê²½):
        - ëª©í‘œ: "Low/Medium/High" ë“±ê¸‰ ì˜ˆì¸¡
        - í‰ê°€: Accuracy, Precision, Recall, F1
        - ì¥ì : ë“±ê¸‰ ë§ì¶”ê¸°ê°€ ì •í™•í•œ ìˆ˜ì¹˜ë³´ë‹¤ ì‰¬ì›€
    
    ============================================================
    ë“±ê¸‰ ê¸°ì¤€ (Percentile):
    ============================================================
    - Low: ì‚¬ìš©ë¥  < P25 (í•˜ìœ„ 25%)
    - Medium: P25 â‰¤ ì‚¬ìš©ë¥  < P75 (ì¤‘ê°„ 50%)
    - High: ì‚¬ìš©ë¥  â‰¥ P75 (ìƒìœ„ 25%)
    """
    
    # ============================================================
    # ì„œë¹„ìŠ¤ â†’ UnifiedCategory ë§¤í•‘
    # ============================================================
    SERVICE_CATEGORY_MAP = {
        # Compute
        'compute engine': 'Compute', 'ec2': 'Compute', 'amazon ec2': 'Compute',
        'cloud functions': 'Compute', 'lambda': 'Compute', 'aws lambda': 'Compute',
        'cloud run': 'Compute', 'ecs': 'Compute', 'fargate': 'Compute',
        'app engine': 'Compute', 'elastic beanstalk': 'Compute',
        
        # Container
        'kubernetes engine': 'Container', 'gke': 'Container',
        'eks': 'Container', 'amazon eks': 'Container',
        
        # Database
        'cloud sql': 'Database', 'rds': 'Database', 'amazon rds': 'Database',
        'aurora': 'Database', 'dynamodb': 'Database', 'bigtable': 'Database',
        'firestore': 'Database', 'elasticache': 'Database', 'redshift': 'Database',
        
        # Storage
        'cloud storage': 'Storage', 's3': 'Storage', 'amazon s3': 'Storage',
        'persistent disk': 'Storage', 'ebs': 'Storage', 'efs': 'Storage',
        
        # Analytics
        'bigquery': 'Analytics', 'athena': 'Analytics', 'dataproc': 'Analytics',
        'emr': 'Analytics', 'kinesis': 'Analytics', 'glue': 'Analytics',
        
        # AI/ML
        'vertex ai': 'AI_ML', 'sagemaker': 'AI_ML', 'automl': 'AI_ML',
        
        # Networking
        'vpc': 'Networking', 'cloud load balancing': 'Networking',
        'elb': 'Networking', 'cloudfront': 'Networking', 'cloud cdn': 'Networking',
        
        # Monitoring
        'cloud monitoring': 'Monitoring', 'cloudwatch': 'Monitoring',
        
        # Security
        'iam': 'Security', 'kms': 'Security', 'waf': 'Security',
        
        # Messaging
        'pub/sub': 'Messaging', 'sns': 'Messaging', 'sqs': 'Messaging',
    }
    
    # ============================================================
    # ë“±ê¸‰ ì •ì˜
    # ============================================================
    USAGE_CLASSES = ['Low', 'Medium', 'High']
    
    
    def __init__(self, config_path='config/focus_config.yaml'):
        """
        ì´ˆê¸°í™”
        """
        super().__init__(config_path)
        
        # ê²½ë¡œ ì„¤ì •
        data_config = self.config['data']
        self.input_path = Path(data_config['resource_grouped_output'])
        self.output_path = Path('results/transfer_learning/ml_classifier_predictions.csv')
        self.model_dir = Path('results/transfer_learning/models/classifier')
        
        # í•™ìŠµ ì„¤ì •
        self.sample_size = 1_000_000       # 100ë§Œê±´
        self.tune_hyperparams = True
        self.n_iter = 15
        self.cv_folds = 3
        self.test_size = 0.2
        
        # ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ ì„ê³„ê°’
        thresholds = self.config['thresholds']['over_provisioning']
        self.cpu_threshold = thresholds['cpu_threshold']
        self.memory_threshold = thresholds['memory_threshold']
        
        # ============================================================
        # Percentile ê¸°ì¤€ (ë“±ê¸‰ ë¶„ë¥˜ìš©)
        # ============================================================
        self.cpu_percentiles = {}    # {'P25': 0.15, 'P75': 0.65}
        self.memory_percentiles = {}
        
        # Feature ì„¤ì •
        self.feature_cols = ['UnifiedCategory', 'ResourceType', 'LogCost', 'HourOfDay', 'DayOfWeek']
        self.categorical_cols = ['UnifiedCategory', 'ResourceType']
        self.numerical_cols = ['LogCost', 'HourOfDay', 'DayOfWeek']
        
        # ëª¨ë¸
        self.cpu_model = None      # RandomForestClassifier
        self.memory_model = None   # RandomForestClassifier
        self.label_encoders = {}
        self.scaler = StandardScaler()
        
        # ë°ì´í„°
        self.df_all = None
        self.df_gcp = None
        self.df_aws = None
        self.df_predictions = None
        self.training_results = {}
    
    
    def _map_to_category(self, service_name):
        """
        ì„œë¹„ìŠ¤ëª… â†’ UnifiedCategory
        """
        if pd.isna(service_name):
            return 'Other'
        
        service_lower = str(service_name).lower().strip()
        
        for key, cat in self.SERVICE_CATEGORY_MAP.items():
            if key in service_lower:
                return cat
        
        if any(kw in service_lower for kw in ['compute', 'instance', 'vm']):
            return 'Compute'
        elif any(kw in service_lower for kw in ['sql', 'database', 'db']):
            return 'Database'
        elif any(kw in service_lower for kw in ['storage', 'bucket', 'disk']):
            return 'Storage'
        elif any(kw in service_lower for kw in ['network', 'vpc', 'cdn']):
            return 'Networking'
        
        return 'Other'
    
    
    def _usage_to_class(self, usage, percentiles):
        """
        ì‚¬ìš©ë¥  â†’ ë“±ê¸‰ ë³€í™˜ (Percentile ê¸°ì¤€)
        
        Args:
            usage: ì‚¬ìš©ë¥  (0~1)
            percentiles: {'P25': 0.15, 'P75': 0.65}
        
        Returns:
            str: 'Low', 'Medium', 'High'
        """
        if usage < percentiles['P25']:
            return 'Low'       # í•˜ìœ„ 25% â†’ ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ ê°€ëŠ¥ì„±
        elif usage < percentiles['P75']:
            return 'Medium'    # ì¤‘ê°„ 50% â†’ ì ì •
        else:
            return 'High'      # ìƒìœ„ 25% â†’ íš¨ìœ¨ì 
    
    
    def load(self):
        """
        ë°ì´í„° ë¡œë“œ
        """
        self.print_step("ë°ì´í„° ë¡œë”©", f"{self.input_path}")
        
        if not self.input_path.exists():
            self.print_error(f"íŒŒì¼ ì—†ìŒ: {self.input_path}")
            return self
        
        self.df_all = pd.read_csv(self.input_path)
        self.print_success(f"ë¡œë“œ ì™„ë£Œ: {len(self.df_all):,}ê±´")
        
        # UnifiedCategory ìƒì„±
        self.df_all['UnifiedCategory'] = self.df_all['ServiceName'].apply(self._map_to_category)
        
        # LogCost ìƒì„±
        cost_col = 'TotalHourlyCost' if 'TotalHourlyCost' in self.df_all.columns else 'BilledCost'
        self.df_all['LogCost'] = np.log1p(
            pd.to_numeric(self.df_all[cost_col], errors='coerce').fillna(0)
        )
        
        # GCP/AWS ë¶„ë¦¬
        gcp_mask = self.df_all['ProviderName'].str.upper().str.contains('GCP|GOOGLE', na=False)
        aws_mask = self.df_all['ProviderName'].str.upper().str.contains('AWS|AMAZON', na=False)
        
        self.df_gcp = self.df_all[gcp_mask].copy()
        self.df_aws = self.df_all[aws_mask].copy()
        
        print(f"\n   â˜ï¸  GCP (í•™ìŠµ): {len(self.df_gcp):,}ê±´")
        print(f"   â˜ï¸  AWS (ì˜ˆì¸¡): {len(self.df_aws):,}ê±´")
        
        # ì¹´í…Œê³ ë¦¬ ë¶„í¬
        print(f"\n   ğŸ“Š UnifiedCategory ë¶„í¬:")
        for cat, cnt in self.df_all['UnifiedCategory'].value_counts().head(8).items():
            print(f"      â€¢ {cat}: {cnt:,}ê±´")
        
        return self
    
    
    def _find_usage_columns(self):
        """
        ì‚¬ìš©ë¥  ì»¬ëŸ¼ ì°¾ê¸°
        """
        cols = self.df_gcp.columns.tolist()
        cpu_col = next((c for c in ['AvgCPUUsage', 'SimulatedCPUUsage', 'CPUUsage'] if c in cols), None)
        mem_col = next((c for c in ['AvgMemoryUsage', 'SimulatedMemoryUsage', 'MemoryUsage'] if c in cols), None)
        return cpu_col, mem_col
    
    
    def _extract_resource_type(self, service_name):
        """
        ë¦¬ì†ŒìŠ¤ íƒ€ì… ì¶”ì¶œ
        """
        if pd.isna(service_name):
            return 'Unknown'
        
        service_lower = str(service_name).lower()
        
        if any(kw in service_lower for kw in ['vm', 'instance', 'ec2', 'compute engine']):
            return 'VM'
        elif any(kw in service_lower for kw in ['container', 'docker', 'ecs', 'gke', 'eks']):
            return 'Container'
        elif any(kw in service_lower for kw in ['function', 'lambda', 'serverless']):
            return 'Function'
        elif any(kw in service_lower for kw in ['sql', 'database', 'rds']):
            return 'Database'
        elif any(kw in service_lower for kw in ['storage', 's3', 'bucket']):
            return 'Storage'
        
        return 'Other'
    
    
    def _prepare_features(self, df):
        """
        Feature ì¤€ë¹„
        """
        df = df.copy()
        
        if 'ResourceType' not in df.columns:
            df['ResourceType'] = df['ServiceName'].apply(self._extract_resource_type)
        
        if 'HourOfDay' not in df.columns:
            if 'ChargePeriodStart' in df.columns:
                df['ChargePeriodStart'] = pd.to_datetime(df['ChargePeriodStart'], errors='coerce')
                df['HourOfDay'] = df['ChargePeriodStart'].dt.hour.fillna(12).astype(int)
                df['DayOfWeek'] = df['ChargePeriodStart'].dt.dayofweek.fillna(3).astype(int)
            else:
                df['HourOfDay'] = 12
                df['DayOfWeek'] = 3
        
        return df
    
    
    def _encode_features(self, df, fit=False):
        """
        Feature ì¸ì½”ë”©
        """
        encoded_data = []
        
        for col in self.categorical_cols:
            if col not in df.columns:
                continue
            
            if fit:
                self.label_encoders[col] = LabelEncoder()
                unique_vals = list(df[col].unique()) + ['Unknown']
                self.label_encoders[col].fit(unique_vals)
            
            values = df[col].fillna('Unknown').astype(str)
            known_classes = set(self.label_encoders[col].classes_)
            values = values.apply(lambda x: x if x in known_classes else 'Unknown')
            
            encoded = self.label_encoders[col].transform(values)
            encoded_data.append(encoded.reshape(-1, 1))
        
        numerical_data = df[self.numerical_cols].fillna(0).values
        
        if fit:
            numerical_scaled = self.scaler.fit_transform(numerical_data)
        else:
            numerical_scaled = self.scaler.transform(numerical_data)
        
        encoded_data.append(numerical_scaled)
        
        return np.hstack(encoded_data)
    
    
    def _get_param_space(self):
        """
        í•˜ì´í¼íŒŒë¼ë¯¸í„° íƒìƒ‰ ê³µê°„
        """
        return {
            'n_estimators': [50, 100, 150, 200],
            'max_depth': [10, 15, 20, 25, None],
            'min_samples_split': [2, 5, 10],
            'min_samples_leaf': [1, 2, 4],
            'max_features': ['sqrt', 'log2', None],
            'class_weight': ['balanced', 'balanced_subsample', None]  # í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬
        }
    
    
    def process(self):
        """
        ëª¨ë¸ í•™ìŠµ (Classification)
        
        ============================================================
        í•µì‹¬ ë³€ê²½:
        1. ì‚¬ìš©ë¥  â†’ ë“±ê¸‰(Low/Medium/High) ë³€í™˜
        2. RandomForestRegressor â†’ RandomForestClassifier
        3. RÂ², MAE â†’ Accuracy, F1-Score
        ============================================================
        """
        self.print_step("RandomForest ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ")
        
        if self.df_gcp is None or len(self.df_gcp) == 0:
            self.print_error("GCP ë°ì´í„° ì—†ìŒ")
            return self
        
        cpu_col, mem_col = self._find_usage_columns()
        if not cpu_col or not mem_col:
            self.print_error(f"ì‚¬ìš©ë¥  ì»¬ëŸ¼ ì—†ìŒ")
            return self
        
        print(f"   ğŸ“‹ Target: CPU={cpu_col}, Memory={mem_col}")
        print(f"   ğŸ“‹ Features: {self.feature_cols}")
        print(f"   ğŸ“‹ Classes: {self.USAGE_CLASSES}")
        
        # Feature ì¤€ë¹„
        df_train = self._prepare_features(self.df_gcp)
        
        df_train[cpu_col] = pd.to_numeric(df_train[cpu_col], errors='coerce')
        df_train[mem_col] = pd.to_numeric(df_train[mem_col], errors='coerce')
        
        df_valid = df_train[
            (df_train[cpu_col] > 0) & (df_train[cpu_col] <= 1) &
            (df_train[mem_col] > 0) & (df_train[mem_col] <= 1)
        ].copy()
        
        print(f"   ğŸ“Š ìœ íš¨ ë°ì´í„°: {len(df_valid):,}ê±´")
        
        # ============================================================
        # Percentile ê³„ì‚° (ë“±ê¸‰ ê¸°ì¤€)
        # ============================================================
        self.cpu_percentiles = {
            'P25': float(np.percentile(df_valid[cpu_col], 25)),
            'P50': float(np.percentile(df_valid[cpu_col], 50)),
            'P75': float(np.percentile(df_valid[cpu_col], 75))
        }
        self.memory_percentiles = {
            'P25': float(np.percentile(df_valid[mem_col], 25)),
            'P50': float(np.percentile(df_valid[mem_col], 50)),
            'P75': float(np.percentile(df_valid[mem_col], 75))
        }
        
        print(f"\n   ğŸ“Š CPU Percentile ê¸°ì¤€:")
        print(f"      â€¢ Low: < {self.cpu_percentiles['P25']*100:.1f}% (í•˜ìœ„ 25%)")
        print(f"      â€¢ Medium: {self.cpu_percentiles['P25']*100:.1f}% ~ {self.cpu_percentiles['P75']*100:.1f}%")
        print(f"      â€¢ High: â‰¥ {self.cpu_percentiles['P75']*100:.1f}% (ìƒìœ„ 25%)")
        
        print(f"\n   ğŸ“Š Memory Percentile ê¸°ì¤€:")
        print(f"      â€¢ Low: < {self.memory_percentiles['P25']*100:.1f}%")
        print(f"      â€¢ Medium: {self.memory_percentiles['P25']*100:.1f}% ~ {self.memory_percentiles['P75']*100:.1f}%")
        print(f"      â€¢ High: â‰¥ {self.memory_percentiles['P75']*100:.1f}%")
        
        # ============================================================
        # ì‚¬ìš©ë¥  â†’ ë“±ê¸‰ ë³€í™˜ (í•µì‹¬!)
        # ============================================================
        df_valid['CPUClass'] = df_valid[cpu_col].apply(
            lambda x: self._usage_to_class(x, self.cpu_percentiles)
        )
        df_valid['MemoryClass'] = df_valid[mem_col].apply(
            lambda x: self._usage_to_class(x, self.memory_percentiles)
        )
        
        # í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
        print(f"\n   ğŸ“Š CPU ë“±ê¸‰ ë¶„í¬:")
        for cls, cnt in df_valid['CPUClass'].value_counts().items():
            print(f"      â€¢ {cls}: {cnt:,}ê±´ ({cnt/len(df_valid)*100:.1f}%)")
        
        print(f"\n   ğŸ“Š Memory ë“±ê¸‰ ë¶„í¬:")
        for cls, cnt in df_valid['MemoryClass'].value_counts().items():
            print(f"      â€¢ {cls}: {cnt:,}ê±´ ({cnt/len(df_valid)*100:.1f}%)")
        
        # ìƒ˜í”Œë§
        if len(df_valid) > self.sample_size:
            df_sample = df_valid.sample(n=self.sample_size, random_state=42)
            print(f"\n   ğŸ“Š ìƒ˜í”Œë§: {self.sample_size:,}ê±´")
        else:
            df_sample = df_valid
        
        # Feature ì¸ì½”ë”©
        X = self._encode_features(df_sample, fit=True)
        y_cpu = df_sample['CPUClass'].values
        y_mem = df_sample['MemoryClass'].values
        
        # Label ì¸ì½”ë”© (ë“±ê¸‰ â†’ ìˆ«ì)
        self.class_encoder = LabelEncoder()
        self.class_encoder.fit(self.USAGE_CLASSES)
        
        y_cpu_encoded = self.class_encoder.transform(y_cpu)
        y_mem_encoded = self.class_encoder.transform(y_mem)
        
        # Train/Test ë¶„í• 
        X_train, X_test, y_cpu_train, y_cpu_test, y_mem_train, y_mem_test = train_test_split(
            X, y_cpu_encoded, y_mem_encoded, test_size=self.test_size, random_state=42
        )
        
        print(f"\n   ğŸ“Š ë°ì´í„° ë¶„í• :")
        print(f"      â€¢ Train: {len(X_train):,}ê±´")
        print(f"      â€¢ Test: {len(X_test):,}ê±´")
        
        # ============================================================
        # í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
        # ============================================================
        best_params = None
        
        if self.tune_hyperparams:
            print(f"\n   ğŸ”§ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹...")
            
            base_model = RandomForestClassifier(random_state=42, n_jobs=-1)
            search = RandomizedSearchCV(
                base_model,
                self._get_param_space(),
                n_iter=self.n_iter,
                cv=self.cv_folds,
                scoring='f1_macro',  # ë‹¤ì¤‘ í´ë˜ìŠ¤ F1
                random_state=42,
                n_jobs=-1,
                verbose=1
            )
            search.fit(X_train, y_cpu_train)
            best_params = search.best_params_
            
            print(f"\n   âœ… ìµœì  íŒŒë¼ë¯¸í„°:")
            for k, v in best_params.items():
                print(f"      â€¢ {k}: {v}")
        
        # ============================================================
        # CPU ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ
        # ============================================================
        print(f"\n   ğŸ”„ CPU ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ...")
        
        if best_params:
            self.cpu_model = RandomForestClassifier(**best_params, random_state=42, n_jobs=-1)
        else:
            self.cpu_model = RandomForestClassifier(
                n_estimators=100, max_depth=20, class_weight='balanced',
                random_state=42, n_jobs=-1
            )
        
        self.cpu_model.fit(X_train, y_cpu_train)
        
        # CPU í‰ê°€
        y_cpu_pred = self.cpu_model.predict(X_test)
        
        cpu_accuracy = accuracy_score(y_cpu_test, y_cpu_pred)
        cpu_precision = precision_score(y_cpu_test, y_cpu_pred, average='macro')
        cpu_recall = recall_score(y_cpu_test, y_cpu_pred, average='macro')
        cpu_f1 = f1_score(y_cpu_test, y_cpu_pred, average='macro')
        
        print(f"\n   âœ… CPU ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥:")
        print(f"      â€¢ Accuracy: {cpu_accuracy*100:.2f}%")
        print(f"      â€¢ Precision: {cpu_precision*100:.2f}%")
        print(f"      â€¢ Recall: {cpu_recall*100:.2f}%")
        print(f"      â€¢ F1-Score: {cpu_f1*100:.2f}%")
        
        # Confusion Matrix
        print(f"\n   ğŸ“Š CPU Confusion Matrix:")
        cpu_cm = confusion_matrix(y_cpu_test, y_cpu_pred)
        self._print_confusion_matrix(cpu_cm, self.USAGE_CLASSES)
        
        # ============================================================
        # Memory ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ
        # ============================================================
        print(f"\n   ğŸ”„ Memory ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ...")
        
        if best_params:
            self.memory_model = RandomForestClassifier(**best_params, random_state=42, n_jobs=-1)
        else:
            self.memory_model = RandomForestClassifier(
                n_estimators=100, max_depth=20, class_weight='balanced',
                random_state=42, n_jobs=-1
            )
        
        self.memory_model.fit(X_train, y_mem_train)
        
        # Memory í‰ê°€
        y_mem_pred = self.memory_model.predict(X_test)
        
        mem_accuracy = accuracy_score(y_mem_test, y_mem_pred)
        mem_precision = precision_score(y_mem_test, y_mem_pred, average='macro')
        mem_recall = recall_score(y_mem_test, y_mem_pred, average='macro')
        mem_f1 = f1_score(y_mem_test, y_mem_pred, average='macro')
        
        print(f"\n   âœ… Memory ë¶„ë¥˜ ëª¨ë¸ ì„±ëŠ¥:")
        print(f"      â€¢ Accuracy: {mem_accuracy*100:.2f}%")
        print(f"      â€¢ Precision: {mem_precision*100:.2f}%")
        print(f"      â€¢ Recall: {mem_recall*100:.2f}%")
        print(f"      â€¢ F1-Score: {mem_f1*100:.2f}%")
        
        # Confusion Matrix
        print(f"\n   ğŸ“Š Memory Confusion Matrix:")
        mem_cm = confusion_matrix(y_mem_test, y_mem_pred)
        self._print_confusion_matrix(mem_cm, self.USAGE_CLASSES)
        
        # ============================================================
        # ê²°ê³¼ ì €ì¥
        # ============================================================
        self.training_results = {
            'model_type': 'Classification',
            'classes': self.USAGE_CLASSES,
            'sample_size': len(df_sample),
            'features': self.feature_cols,
            'cpu_percentiles': self.cpu_percentiles,
            'memory_percentiles': self.memory_percentiles,
            'best_params': best_params,
            'cpu': {
                'accuracy': float(cpu_accuracy),
                'precision': float(cpu_precision),
                'recall': float(cpu_recall),
                'f1': float(cpu_f1)
            },
            'memory': {
                'accuracy': float(mem_accuracy),
                'precision': float(mem_precision),
                'recall': float(mem_recall),
                'f1': float(mem_f1)
            }
        }
        
        # Feature Importance
        print(f"\n   ğŸ“Š Feature Importance (CPU):")
        feature_names = self.categorical_cols + self.numerical_cols
        for name, imp in sorted(zip(feature_names, self.cpu_model.feature_importances_), 
                                key=lambda x: x[1], reverse=True):
            print(f"      â€¢ {name}: {imp:.4f}")
        
        # Regression vs Classification ë¹„êµ
        self._compare_with_regression()
        
        return self
    
    
    def _print_confusion_matrix(self, cm, classes):
        """
        Confusion Matrix ì¶œë ¥
        """
        print(f"      {'':>10} ", end='')
        for cls in classes:
            print(f"{cls:>8}", end='')
        print()
        
        for i, cls in enumerate(classes):
            print(f"      {cls:>10} ", end='')
            for j in range(len(classes)):
                print(f"{cm[i][j]:>8,}", end='')
            print()
    
    
    def _compare_with_regression(self):
        """
        Regression ê²°ê³¼ì™€ ë¹„êµ
        """
        # Regression ê²°ê³¼ (ì´ì „ ëŒ€í™”ì—ì„œ í™•ì¸ëœ ê°’)
        reg_results = {
            'cpu_r2': 0.0895,
            'memory_r2': 0.0947,
            'description': 'RÂ² < 0.1 â†’ ì˜ˆì¸¡ë ¥ ê±°ì˜ ì—†ìŒ'
        }
        
        print(f"\n{'='*80}")
        print("ğŸ“Š Regression vs Classification ë¹„êµ")
        print(f"{'='*80}")
        
        print(f"\n   ğŸ“ˆ Regression (ê¸°ì¡´):")
        print(f"      â€¢ CPU RÂ²: {reg_results['cpu_r2']:.4f}")
        print(f"      â€¢ Memory RÂ²: {reg_results['memory_r2']:.4f}")
        print(f"      âš ï¸ {reg_results['description']}")
        
        print(f"\n   ğŸ“Š Classification (ë³€ê²½):")
        print(f"      â€¢ CPU Accuracy: {self.training_results['cpu']['accuracy']*100:.2f}%")
        print(f"      â€¢ CPU F1-Score: {self.training_results['cpu']['f1']*100:.2f}%")
        print(f"      â€¢ Memory Accuracy: {self.training_results['memory']['accuracy']*100:.2f}%")
        print(f"      â€¢ Memory F1-Score: {self.training_results['memory']['f1']*100:.2f}%")
        
        # ëœë¤ ì¶”ì¸¡ ëŒ€ë¹„ ê°œì„ ë„ (3ê°œ í´ë˜ìŠ¤ â†’ 33% ê¸°ì¤€)
        random_baseline = 33.33
        cpu_improvement = self.training_results['cpu']['accuracy'] * 100 - random_baseline
        mem_improvement = self.training_results['memory']['accuracy'] * 100 - random_baseline
        
        print(f"\n   ğŸ“Š ëœë¤ ì¶”ì¸¡(33%) ëŒ€ë¹„ ê°œì„ :")
        print(f"      â€¢ CPU: +{cpu_improvement:.1f}%p")
        print(f"      â€¢ Memory: +{mem_improvement:.1f}%p")
        
        print(f"\n   âœ… ê²°ë¡ : Classificationì´ ë” íš¨ê³¼ì ")
        print(f"{'='*80}")
    
    
    def predict(self):
        """
        AWS ë°ì´í„°ì— ë“±ê¸‰ ì˜ˆì¸¡
        """
        self.print_step("AWS ì‚¬ìš©ë¥  ë“±ê¸‰ ì˜ˆì¸¡")
        
        if self.cpu_model is None:
            self.print_error("ë¨¼ì € process() ì‹¤í–‰")
            return self
        
        if self.df_aws is None or len(self.df_aws) == 0:
            self.print_warning("AWS ë°ì´í„° ì—†ìŒ")
            return self
        
        # Feature ì¤€ë¹„
        df_pred = self._prepare_features(self.df_aws)
        X = self._encode_features(df_pred, fit=False)
        
        # ì˜ˆì¸¡
        cpu_class_encoded = self.cpu_model.predict(X)
        mem_class_encoded = self.memory_model.predict(X)
        
        # ë””ì½”ë”© (ìˆ«ì â†’ ë“±ê¸‰)
        cpu_class = self.class_encoder.inverse_transform(cpu_class_encoded)
        mem_class = self.class_encoder.inverse_transform(mem_class_encoded)
        
        # ê²°ê³¼ ì €ì¥
        self.df_predictions = df_pred.copy()
        self.df_predictions['PredictedCPUClass'] = cpu_class
        self.df_predictions['PredictedMemoryClass'] = mem_class
        
        # ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ = Low ë“±ê¸‰
        self.df_predictions['IsOverProvisioned'] = (
            (self.df_predictions['PredictedCPUClass'] == 'Low') |
            (self.df_predictions['PredictedMemoryClass'] == 'Low')
        )
        
        # í†µê³„
        print(f"\n   ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼:")
        print(f"      â€¢ ì „ì²´: {len(self.df_predictions):,}ê±´")
        
        print(f"\n   ğŸ“Š CPU ë“±ê¸‰ ë¶„í¬:")
        for cls, cnt in self.df_predictions['PredictedCPUClass'].value_counts().items():
            print(f"      â€¢ {cls}: {cnt:,}ê±´ ({cnt/len(self.df_predictions)*100:.1f}%)")
        
        print(f"\n   ğŸ“Š Memory ë“±ê¸‰ ë¶„í¬:")
        for cls, cnt in self.df_predictions['PredictedMemoryClass'].value_counts().items():
            print(f"      â€¢ {cls}: {cnt:,}ê±´ ({cnt/len(self.df_predictions)*100:.1f}%)")
        
        over_prov = self.df_predictions['IsOverProvisioned'].sum()
        print(f"\n   ğŸš¨ ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ (Low ë“±ê¸‰):")
        print(f"      â€¢ {over_prov:,}ê±´ ({over_prov/len(self.df_predictions)*100:.1f}%)")
        
        return self
    
    
    def save(self):
        """
        ê²°ê³¼ ì €ì¥
        """
        self.print_step("ê²°ê³¼ ì €ì¥")
        
        self.ensure_dir(self.output_path.parent)
        self.ensure_dir(self.model_dir)
        
        # ì˜ˆì¸¡ ê²°ê³¼
        if self.df_predictions is not None:
            self.df_predictions.to_csv(self.output_path, index=False)
            print(f"   ğŸ“‚ ì˜ˆì¸¡ ê²°ê³¼: {self.output_path}")
        
        # ëª¨ë¸ ì €ì¥
        if self.cpu_model is not None:
            joblib.dump(self.cpu_model, self.model_dir / 'cpu_classifier.joblib')
            joblib.dump(self.memory_model, self.model_dir / 'memory_classifier.joblib')
            joblib.dump(self.label_encoders, self.model_dir / 'label_encoders.joblib')
            joblib.dump(self.scaler, self.model_dir / 'scaler.joblib')
            joblib.dump(self.class_encoder, self.model_dir / 'class_encoder.joblib')
            print(f"   ğŸ“‚ ëª¨ë¸: {self.model_dir}")
        
        # í•™ìŠµ ê²°ê³¼ JSON
        with open(self.model_dir / 'training_results.json', 'w') as f:
            json.dump(self.training_results, f, indent=2)
        
        # ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹ë§Œ
        if self.df_predictions is not None:
            over_path = self.output_path.parent / 'classifier_overprovisioned.csv'
            df_over = self.df_predictions[self.df_predictions['IsOverProvisioned']]
            if len(df_over) > 0:
                df_over.to_csv(over_path, index=False)
                print(f"   ğŸ“‚ ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹: {over_path} ({len(df_over):,}ê±´)")
        
        self.print_success("ì €ì¥ ì™„ë£Œ")
        return self
    
    
    def run(self):
        """
        ì „ì²´ ì‹¤í–‰
        """
        return (self.load()
                .process()
                .predict()
                .save())
    
    
    def get_results(self):
        """
        ê²°ê³¼ ë°˜í™˜
        """
        return (self.df_predictions, self.training_results)


# ============================================================
# ë©”ì¸ ì‹¤í–‰
# ============================================================
if __name__ == "__main__":
    
    print("\n" + "="*80)
    print("ğŸš€ ML ì‚¬ìš©ë¥  ë¶„ë¥˜ ëª¨ë¸ (Regression â†’ Classification)")
    print("="*80)
    print("ğŸ“Œ í•µì‹¬ ë³€ê²½:")
    print("   â€¢ Regression: CPU=0.45 ì˜ˆì¸¡ â†’ RÂ² 0.08 (ì‹¤íŒ¨)")
    print("   â€¢ Classification: Low/Medium/High ì˜ˆì¸¡ â†’ Accuracy/F1 (ê°œì„ )")
    print("ğŸ“Œ ë“±ê¸‰ ê¸°ì¤€:")
    print("   â€¢ Low: í•˜ìœ„ 25% (ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹)")
    print("   â€¢ Medium: ì¤‘ê°„ 50% (ì ì •)")
    print("   â€¢ High: ìƒìœ„ 25% (íš¨ìœ¨ì )")
    print("="*80)
    
    classifier = MLUsageClassifier('config/focus_config.yaml')
    classifier.sample_size = 1_000_000
    classifier.tune_hyperparams = True
    classifier.n_iter = 15
    
    classifier.run()
    
    df_pred, results = classifier.get_results()
    
    print(f"\nâœ… ì™„ë£Œ!")
    if results:
        print(f"   CPU Accuracy: {results['cpu']['accuracy']*100:.2f}%")
        print(f"   CPU F1-Score: {results['cpu']['f1']*100:.2f}%")