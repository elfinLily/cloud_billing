"""
processed í´ë”ì˜ ëª¨ë“  FOCUS ë°ì´í„° ë¶„ì„

1. data/processed/ í´ë”ì˜ ëª¨ë“  .csv íŒŒì¼ ë¡œë“œ
2. ê° íŒŒì¼ë³„ë¡œ 2íŒ¨í„´ íƒì§€ (ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹, ë¯¸ì‚¬ìš© ë¦¬ì†ŒìŠ¤)
3. CloudProvider, PatternType ì»¬ëŸ¼ ì¶”ê°€
4. í•˜ë‚˜ì˜ .csv.gzë¡œ í†µí•© ì €ì¥
"""

import pandas as pd
import yaml
from pathlib import Path
import logging

from focus_patterns import OverProvisioningDetector, UnusedResourceDetector


class AllFocusAnalyzer:
    """ì „ì²´ FOCUS ë°ì´í„° ë¶„ì„ê¸°"""
    
    def __init__(self, config_path='config/focus_config.yaml'):
        """
        ì´ˆê¸°í™”
        
        Args:
            config_path: ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        # ì„¤ì • ë¡œë“œ
        with open(config_path, 'r', encoding='utf-8') as f:
            self.config = yaml.safe_load(f)
        
        # ê²½ë¡œ ì„¤ì •
        self.focus_folder = Path(self.config['data']['focus_folder'])
        self.output_path = Path(self.config['data']['detected_patterns_output'])
        
        # ë¡œê¹… ì„¤ì •
        logging.basicConfig(level=logging.INFO)
        self.logger = logging.getLogger(__name__)
        
        # ê²°ê³¼ ì €ì¥
        self.all_results = []
    
    
    def find_focus_files(self):
        """
        processed í´ë”ì˜ ëª¨ë“  CSV íŒŒì¼ ì°¾ê¸°
        
        Returns:
            list: CSV íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        print("="*100)
        print("ğŸ” FOCUS íŒŒì¼ ê²€ìƒ‰ ì¤‘...")
        print("="*100)
        print(f"   ğŸ“‚ í´ë”: {self.focus_folder}")
        
        csv_files = list(self.focus_folder.glob('*.csv'))
        
        print(f"\nâœ… ë°œê²¬ëœ íŒŒì¼: {len(csv_files)}ê°œ")
        for i, file in enumerate(csv_files, 1):
            print(f"   {i}. {file.name}")
        
        print("\n" + "="*100)
        
        return csv_files
    
    
    def detect_cloud_provider(self, df, filename):
        """
        CloudProvider ìë™ ê°ì§€
        
        Args:
            df: DataFrame
            filename: íŒŒì¼ëª…
        
        Returns:
            str: 'AWS' or 'GCP' or 'Unknown'
        """
        # 1. íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ
        filename_lower = filename.lower()
        if 'aws' in filename_lower:
            return 'AWS'
        elif 'gcp' in filename_lower or 'google' in filename_lower:
            return 'GCP'
        
        # 2. ProviderName ì»¬ëŸ¼ì—ì„œ ì¶”ì¶œ
        if 'ProviderName' in df.columns:
            providers = df['ProviderName'].unique()
            if len(providers) == 1:
                provider = providers[0]
                if 'AWS' in provider or 'Amazon' in provider:
                    return 'AWS'
                elif 'Google' in provider or 'GCP' in provider:
                    return 'GCP'
        
        return 'Unknown'
    
    
    def analyze_file(self, file_path):
        """
        ë‹¨ì¼ íŒŒì¼ ë¶„ì„
        
        Args:
            file_path: CSV íŒŒì¼ ê²½ë¡œ
        
        Returns:
            dict: {'over_provisioned': DataFrame, 'unused': DataFrame, 'provider': str}
        """
        print("\n" + "="*100)
        print(f"ğŸ“Š ë¶„ì„ ì‹œì‘: {file_path.name}")
        print("="*100)
        
        # ë°ì´í„° ë¡œë“œ
        df = pd.read_csv(file_path, low_memory=False)
        print(f"   âœ… ë¡œë“œ ì™„ë£Œ: {len(df):,}ê±´")
        
        # CloudProvider ê°ì§€
        provider = self.detect_cloud_provider(df, file_path.name)
        print(f"   â˜ï¸  Provider: {provider}")
        
        # íŒ¨í„´ 1: ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹
        detector1 = OverProvisioningDetector(df, self.config)
        over_prov = detector1.detect()
        
        if len(over_prov) > 0:
            over_prov['CloudProvider'] = provider
            over_prov['PatternType'] = 'OverProvisioning'
        
        # íŒ¨í„´ 2: ë¯¸ì‚¬ìš© ë¦¬ì†ŒìŠ¤
        detector2 = UnusedResourceDetector(df, self.config)
        unused = detector2.detect()
        
        if len(unused) > 0:
            unused['CloudProvider'] = provider
            unused['PatternType'] = 'Unused'
        
        return {
            'over_provisioned': over_prov,
            'unused': unused,
            'provider': provider
        }
    
    
    def merge_results(self):
        """
        ëª¨ë“  ê²°ê³¼ ë³‘í•©
        
        Returns:
            DataFrame: í†µí•©ëœ íƒì§€ ê²°ê³¼
        """
        print("\n" + "="*100)
        print("ğŸ”— ê²°ê³¼ ë³‘í•© ì¤‘...")
        print("="*100)
        
        all_patterns = []
        
        for result in self.all_results:
            if len(result['over_provisioned']) > 0:
                all_patterns.append(result['over_provisioned'])
            
            if len(result['unused']) > 0:
                all_patterns.append(result['unused'])
        
        if len(all_patterns) == 0:
            print("âš ï¸  íƒì§€ëœ íŒ¨í„´ì´ ì—†ìŠµë‹ˆë‹¤!")
            return pd.DataFrame()
        
        # ë³‘í•©
        merged = pd.concat(all_patterns, ignore_index=True)
        
        print(f"âœ… ë³‘í•© ì™„ë£Œ: {len(merged):,}ê±´")
        print(f"\nğŸ“Š CloudProviderë³„:")
        for provider, count in merged['CloudProvider'].value_counts().items():
            print(f"   â€¢ {provider}: {count:,}ê±´")
        
        print(f"\nğŸ“Š PatternTypeë³„:")
        for pattern, count in merged['PatternType'].value_counts().items():
            print(f"   â€¢ {pattern}: {count:,}ê±´")
        
        print("\n" + "="*100)
        
        return merged
    
    
    def save_results(self, df):
        """
        ê²°ê³¼ ì €ì¥ (.csv.gz)
        
        Args:
            df: ì €ì¥í•  DataFrame
        """
        if len(df) == 0:
            print("âš ï¸  ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print("\n" + "="*100)
        print("ğŸ’¾ ê²°ê³¼ ì €ì¥ ì¤‘...")
        print("="*100)
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # ì €ì¥ (ì••ì¶•)
        df.to_csv(
            self.output_path,
            index=False,
            encoding='utf-8-sig',
            compression='gzip'
        )
        
        size_mb = self.output_path.stat().st_size / 1024**2
        
        print(f"\nâœ… ì €ì¥ ì™„ë£Œ!")
        print(f"   ğŸ“‚ ê²½ë¡œ: {self.output_path}")
        print(f"   ğŸ“Š ë ˆì½”ë“œ: {len(df):,}ê±´")
        print(f"   ğŸ’¾ í¬ê¸°: {size_mb:.1f} MB")
        print("\n" + "="*100)
    
    
    def print_summary(self, df):
        """
        ìµœì¢… ìš”ì•½ í†µê³„
        
        Args:
            df: í†µí•© ê²°ê³¼ DataFrame
        """
        if len(df) == 0:
            return
        
        print("\n" + "="*100)
        print("ğŸ“Š ìµœì¢… ë¶„ì„ ìš”ì•½")
        print("="*100)
        
        print(f"\nâœ… ì´ íƒì§€ ê±´ìˆ˜: {len(df):,}ê±´")
        
        # CloudProvider Ã— PatternType êµì°¨í‘œ
        print(f"\nğŸ“Š CloudProvider Ã— PatternType:")
        crosstab = pd.crosstab(df['CloudProvider'], df['PatternType'], margins=True)
        print(crosstab)
        
        # ë¹„ìš© í†µê³„
        cost_cols = [col for col in df.columns if 'cost' in col.lower() or 'savings' in col.lower()]
        
        if cost_cols:
            print(f"\nğŸ’° ë¹„ìš© í†µê³„:")
            for provider in df['CloudProvider'].unique():
                if provider == 'All':
                    continue
                
                provider_df = df[df['CloudProvider'] == provider]
                
                # ê³¼ë‹¤ í”„ë¡œë¹„ì €ë‹
                over_prov = provider_df[provider_df['PatternType'] == 'OverProvisioning']
                if len(over_prov) > 0 and 'PotentialSavings' in over_prov.columns:
                    savings = over_prov['PotentialSavings'].sum()
                    print(f"   â€¢ {provider} ê³¼ë‹¤í”„ë¡œë¹„ì €ë‹ ì ˆê° ê°€ëŠ¥: ${savings:,.2f}/ì›”")
                
                # ë¯¸ì‚¬ìš© ë¦¬ì†ŒìŠ¤
                unused = provider_df[provider_df['PatternType'] == 'Unused']
                if len(unused) > 0 and 'WastedCost' in unused.columns:
                    waste = unused['WastedCost'].sum()
                    print(f"   â€¢ {provider} ë¯¸ì‚¬ìš© ë¦¬ì†ŒìŠ¤ ë‚­ë¹„: ${waste:,.2f}/ì›”")
        
        print("\n" + "="*100)
    
    
    def run(self):
        """
        ì „ì²´ ë¶„ì„ ì‹¤í–‰
        
        Returns:
            DataFrame: í†µí•© ê²°ê³¼
        """
        # 1. íŒŒì¼ ì°¾ê¸°
        csv_files = self.find_focus_files()
        
        if len(csv_files) == 0:
            print("âŒ ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!")
            return pd.DataFrame()
        
        # 2. ê° íŒŒì¼ ë¶„ì„
        for file_path in csv_files:
            result = self.analyze_file(file_path)
            self.all_results.append(result)
        
        # 3. ê²°ê³¼ ë³‘í•©
        merged_df = self.merge_results()
        
        # 4. ì €ì¥
        self.save_results(merged_df)
        
        # 5. ìš”ì•½
        self.print_summary(merged_df)
        
        print("\nâœ… ëª¨ë“  ë¶„ì„ ì™„ë£Œ!")
        
        return merged_df


# ==================== ë©”ì¸ ì‹¤í–‰ ====================
if __name__ == "__main__":
    
    print("="*100)
    print("ğŸš€ ì „ì²´ FOCUS ë°ì´í„° ë¶„ì„ ì‹œì‘")
    print("="*100)
    
    analyzer = AllFocusAnalyzer()
    results = analyzer.run()
    
    print("\n" + "="*100)
    print("ğŸ‰ ì™„ë£Œ!")
    print("="*100)