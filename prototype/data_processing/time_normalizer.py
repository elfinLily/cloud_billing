# -*- coding: utf-8 -*-
"""
ì‹œê°„ ë²”ìœ„ ì •ê·œí™” (Time Range Normalization)
ChargePeriodStart ~ ChargePeriodEndë¥¼ 1ì‹œê°„ ë‹¨ìœ„ë¡œ í™•ì¥
"""

import yaml
import polars as pl
from pathlib import Path
from datetime import timedelta
from pipeline_base import PipelineBase

class TimeNormalizer(PipelineBase):
    """
    ì‹œê°„ ë²”ìœ„ë¥¼ 1ì‹œê°„ ë‹¨ìœ„ë¡œ ì •ê·œí™”í•˜ëŠ” í´ë˜ìŠ¤
    
    ì£¼ìš” ê¸°ëŠ¥:
    - ChargePeriodStart ~ ChargePeriodEnd ì‚¬ì´ì˜ ëª¨ë“  ì‹œê°„(hour)ì„ ê°œë³„ ë ˆì½”ë“œë¡œ í™•ì¥
    - ê° ì‹œê°„ ìŠ¬ë¡¯ì— ì›ë³¸ ë°ì´í„°ì˜ ë¹„ìš©ì„ ì‹œê°„ ë¹„ìœ¨ë¡œ ë¶„ë°°
    """
    
    def __init__(self, config_path='config/focus_config.yaml'):
        """
        ì´ˆê¸°í™”
        
        Args:
            df (DataFrame): FOCUS í˜•ì‹ì˜ ì²­êµ¬ ë°ì´í„°
                í•„ìˆ˜ ì»¬ëŸ¼: ChargePeriodStart, ChargePeriodEnd, BilledCost
        """
        super().__init__(config_path)

        data_config = self.config['data']
        self.output_path = Path(data_config['time_normalized_output'])
        self.gcp_data_path = Path(data_config['gcp_focus_output'])
        self.aws_data_path = Path(data_config['aws_focus_output'])

        self.df_all = None
        self.df_time_normalized = None

    
    def load(self):
        """
        FOCUS í˜•ì‹ì˜ billing ë°ì´í„° CSV ë¡œë“œ
        
        Returns:
            DataFrame: ì›ë³¸ ë°ì´í„°
        """
        print("="*100)
        print(f"ğŸ”„ ë°ì´í„° ë¡œë”©: {self.aws_data_path} / {self.gcp_data_path}")
        print("="*100)
        
        dfs_to_concat = []

        if self.gcp_data_path.exists():
            df_gcp = pl.read_csv(self.gcp_data_path, infer_schema_length=0)
            dfs_to_concat.append(df_gcp)
            print(f"   âœ… GCP: {len(df_gcp):,}ê±´, {len(df_gcp.columns)}ê°œ ì»¬ëŸ¼")
        
        # AWS ë°ì´í„° ë¡œë“œ
        if self.aws_data_path.exists():
            df_aws = pl.read_csv(self.aws_data_path, infer_schema_length=0)
            dfs_to_concat.append(df_aws)
            print(f"   âœ… AWS: {len(df_aws):,}ê±´, {len(df_aws.columns)}ê°œ ì»¬ëŸ¼")
        
        if not dfs_to_concat:
            raise FileNotFoundError(
                f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤:\n"
                f"   GCP: {self.gcp_data_path}\n"
                f"   AWS: {self.aws_data_path}"
            )

        self.df_all = pl.concat(dfs_to_concat, how='diagonal')

        print(f"\nâœ… ë¡œë“œ ì™„ë£Œ!")
        print(f"   ğŸ“Š ì´ ë ˆì½”ë“œ: {len(self.df_all):,}ê±´")

        return self.df_all
    
    def _validate_columns(self):
        """
        í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€ ê²€ì¦
        
        í•„ìˆ˜ ì»¬ëŸ¼: ChargePeriodStart, ChargePeriodEnd
        """
        required_cols = ['ChargePeriodStart', 'ChargePeriodEnd']
        missing = [col for col in required_cols if col not in self.df_all.columns]
        
        if missing:
            raise ValueError(f"âŒ í•„ìˆ˜ ì»¬ëŸ¼ ëˆ„ë½: {missing}")
        
        print(f"\nâœ… í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦ ì™„ë£Œ: {required_cols}")

        return self
    
    
    def _convert_datetime(self):
        """
        ë‚ ì§œ/ì‹œê°„ ì»¬ëŸ¼ì„ datetime íƒ€ì…ìœ¼ë¡œ ë³€í™˜
        """
        print("\nğŸ• ë‚ ì§œ/ì‹œê°„ í˜•ì‹ ë³€í™˜ ì¤‘...")
        
        # Polars ë‚ ì§œ ë³€í™˜
        self.df_all = self.df_all.with_columns([
            pl.col('ChargePeriodStart').str.strptime(pl.Datetime, format='%Y-%m-%d %H:%M:%S', strict=False),
            pl.col('ChargePeriodEnd').str.strptime(pl.Datetime, format='%Y-%m-%d %H:%M:%S', strict=False)
        ])
        
        if 'BilledCost' in self.df_all.columns:
            self.df_all = self.df_all.with_columns([
                pl.col('BilledCost').cast(pl.Float64, strict=False)
            ])

        # null ì œê±°
        null_count = self.df_all.filter(
            pl.col('ChargePeriodStart').is_null() | 
            pl.col('ChargePeriodEnd').is_null() |
            pl.col('BilledCost').is_null()
        ).height

        if null_count > 0:
            print(f"âš ï¸  ë³€í™˜ ì‹¤íŒ¨: {null_count}ê±´ ì œê±°")
            self.df_all = self.df_all.drop_nulls(subset=['ChargePeriodStart', 'ChargePeriodEnd', 'BilledCost'])

        print(f"âœ… ë³€í™˜ ì™„ë£Œ: {len(self.df_all):,}ê±´")

        return self
    
    
    def normalize(self, distribute_cost=True):
        """
        ì‹œê°„ ë²”ìœ„ë¥¼ 1ì‹œê°„ ë‹¨ìœ„ë¡œ í™•ì¥
        
        Args:
            distribute_cost (bool): Trueë©´ ë¹„ìš©ì„ ì‹œê°„ë³„ë¡œ ê· ë“± ë¶„ë°°, Falseë©´ ì›ë³¸ ë¹„ìš© ìœ ì§€
        
        Returns:
            DataFrame: ì‹œê°„ë³„ë¡œ í™•ì¥ëœ ë°ì´í„°
                - HourlyTimestamp: ê° ì‹œê°„ ìŠ¬ë¡¯ì˜ ì‹œì‘ ì‹œê°
                - OriginalDurationHours: ì›ë³¸ ë ˆì½”ë“œì˜ ì´ ì‹œê°„
                - HourlyCost: ì‹œê°„ë‹¹ ë¶„ë°°ëœ ë¹„ìš© (distribute_cost=Trueì¸ ê²½ìš°)
        
        Steps:
            1. ê° ë ˆì½”ë“œì˜ Start ~ End ì‹œê°„ ì°¨ì´ ê³„ì‚°
            2. ì‹œê°„ ì°¨ì´ë¥¼ 1ì‹œê°„ ë‹¨ìœ„ë¡œ ë¶„í•´
            3. ê° ì‹œê°„ ìŠ¬ë¡¯ì„ ê°œë³„ í–‰ìœ¼ë¡œ ìƒì„±
            4. ë¹„ìš©ì„ ì‹œê°„ ìˆ˜ë¡œ ë‚˜ëˆ ì„œ ë¶„ë°° (ì˜µì…˜)
        """
        print("\n" + "="*100)
        print("ğŸ”„ ì‹œê°„ ì •ê·œí™” ì‹œì‘")
        print("="*100)
        
        total_records = len(self.df_all)
        print(f"ğŸ“Š ì²˜ë¦¬ ëŒ€ìƒ: {total_records:,}ê±´")
        print(f"ğŸ’° ë¹„ìš© ë¶„ë°°: {'ON (ì‹œê°„ë³„ ê· ë“± ë¶„ë°°)' if distribute_cost else 'OFF (ì›ë³¸ ìœ ì§€)'}")
        
        # ì‹œê°„ ì°¨ì´ ê³„ì‚° (ì‹œê°„ ë‹¨ìœ„, ë²¡í„° ì—°ì‚°)
        df_with_duration = self.df_all.with_columns([
            ((pl.col('ChargePeriodEnd') - pl.col('ChargePeriodStart')).dt.total_seconds() / 3600)
            .clip(lower_bound=1)
            .cast(pl.Int64)
            .alias('OriginalDurationHours')
        ])
        
        # ì‹œê°„ë‹¹ ë¹„ìš© ê³„ì‚° (ë²¡í„° ì—°ì‚°)
        if distribute_cost:
            df_with_duration = df_with_duration.with_columns([
                (pl.col('BilledCost') / pl.col('OriginalDurationHours')).alias('HourlyCost')
            ])
        else:
            df_with_duration = df_with_duration.with_columns([
                pl.col('BilledCost').alias('HourlyCost')
            ])
        
        df_with_duration = df_with_duration.with_row_count('_row_id')
        
        print("\n   ë³µì œ ë° í™•ì¥ ì¤‘...")
        
        df_with_duration = df_with_duration.with_columns([
            pl.int_ranges(pl.col('OriginalDurationHours')).alias('hour_offsets')
        ])

        # í–‰í™•ì¥
        df_expanded = df_with_duration.explode('hour_offsets')

        # ì‹œê°„ ê³„ì‚°
        self.df_time_normalized = df_expanded.with_columns([
            (pl.col('ChargePeriodStart') + pl.duration(hours=pl.col('hour_offsets')))
            .alias('HourlyTimestamp')
        ])

        # ë¶ˆí•„ìš” ì»¬ëŸ¼ ì œê±°
        cols_to_drop = ['_row_id', 'hour_offsets']
        self.df_time_normalized = self.df_time_normalized.drop([c for c in cols_to_drop if c in self.df_time_normalized.columns])
    
        
        print(f"\nâœ… í™•ì¥ ì™„ë£Œ!")
        print(f"   ì›ë³¸ ë ˆì½”ë“œ: {total_records:,}ê±´")
        print(f"   í™•ì¥ëœ ë ˆì½”ë“œ: {len(self.df_time_normalized):,}ê±´")
        print(f"   í‰ê·  í™•ì¥ ë°°ìœ¨: {len(self.df_time_normalized) / total_records:.1f}x")

        print("="*100)

        return self
    
    
    def get_hourly_summary(self):
        """
        ì‹œê°„ë³„ ìš”ì•½ í†µê³„ ìƒì„±
             
        Returns:
            DataFrame: ì‹œê°„ë³„ ì§‘ê³„ ë°ì´í„°
                ì»¬ëŸ¼: HourlyTimestamp, RecordCount, TotalCost, AvgCost
        """
        print("\nğŸ“Š ì‹œê°„ë³„ ìš”ì•½ í†µê³„ ìƒì„± ì¤‘...")
        
        summary = self.df_time_normalized.group_by('HourlyTimestamp').agg([
            pl.count().alias('RecordCount'),
            pl.col('HourlyCost').sum().alias('TotalCost'),
            pl.col('HourlyCost').mean().alias('AvgCost')
        ]).sort('HourlyTimestamp')
        self.summary = summary

        print(f"âœ… ìš”ì•½ ì™„ë£Œ: {len(summary):,}ê°œ ì‹œê°„ ìŠ¬ë¡¯")
        
        return self
    
    def save(self):
        """
        ì‹œê°„ ì •ê·œí™” ë°ì´í„° CSV ì €ì¥
        """
        if self.df_time_normalized is None:
            raise ValueError("âŒ ë³€í™˜ì„ ë¨¼ì € ìˆ˜í–‰í•˜ì„¸ìš”: normalize()")
        
        print("="*100)
        print(f"ğŸ’¾ ì‹œê°„ ì •ê·œí™” íŒŒì¼ ì €ì¥ ì¤‘: {self.output_path}")
        print("="*100)
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.output_path.parent.mkdir(parents=True, exist_ok=True)
        
        # CSV ì €ì¥
        self.df_time_normalized.write_csv(self.output_path)
        
        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size_mb = self.output_path.stat().st_size / 1024**2
        
        print(f"\nâœ… ì €ì¥ ì™„ë£Œ!")
        print(f"   ğŸ“‚ ê²½ë¡œ: {self.output_path}")
        print(f"   ğŸ’¾ í¬ê¸°: {file_size_mb:.1f} MB")
        print("="*100)
        
        return self
    
    def run(self):
        """
        ì „ì²´ ì‹œê°„ ì •ê·œí™” í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰: ë¡œë“œ â†’ ë³€í™˜ â†’ ì €ì¥ â†’ ìš”ì•½
        
        Returns:
            tuple: (DataFrame, ìš”ì•½ í†µê³„, ì¶œë ¥ íŒŒì¼ ê²½ë¡œ)
        """
        return (self.load()
                ._validate_columns()
                ._convert_datetime()
                .normalize(distribute_cost=True)
                .save()
                .get_hourly_summary())
    
    def get_results(self):
        """
        ë¶„ì„ ê²°ê³¼ ë°˜í™˜

        Returns:
            tuple: (ì •ê·œí™” ë°ì´í„°, ìš”ì•½ í†µê³„, ì¶œë ¥ ê²½ë¡œ)
        """
        return (
            self.df_time_normalized,
            getattr(self, 'summary', None),
            self.output_path
        )


if __name__ == "__main__":
    import yaml
    
    print("\nğŸš€ FOCUS í˜•ì‹ ë°ì´í„° â†’ ì‹œê°„ ì •ê·œí™”")

    normalizer = TimeNormalizer('config/focus_config.yaml')
    normalizer.run()
    
    # ê²°ê³¼ ì¡°íšŒ
    df_time_normalized, summary, output_path = normalizer.get_results()
    
    print(f"\nâœ… ì‹œê°„ ì •ê·œí™” ì™„ë£Œ!")
    print(f"ğŸ“‚ ì¶œë ¥ íŒŒì¼: {output_path}")
    
    if summary is not None:
        print(f"\nì‹œê°„ë³„ ìš”ì•½ (ì²˜ìŒ 10í–‰):")
        print(summary.head(10))

    
