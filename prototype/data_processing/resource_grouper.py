# -*- coding: utf-8 -*-
"""
ë¦¬ì†ŒìŠ¤ë³„ ê·¸ë£¹í™” (Resource Grouping)
ì‹œê°„ ì •ê·œí™”ëœ ë°ì´í„°ë¥¼ ResourceIdë³„ë¡œ ê·¸ë£¹í™”í•˜ì—¬ ì‹œê°„ë³„ ì§‘ê³„
"""

import polars as pl
from pathlib import Path
from pipeline_base import PipelineBase


class ResourceGrouper(PipelineBase):
    """
    ë¦¬ì†ŒìŠ¤ë³„ ì‹œê°„ ë‹¨ìœ„ ê·¸ë£¹í™” í´ë˜ìŠ¤
    
    ì£¼ìš” ê¸°ëŠ¥:
    - ì‹œê°„ ì •ê·œí™”ëœ ë°ì´í„°ë¥¼ ResourceId + HourlyTimestampë¡œ ê·¸ë£¹í™”
    - ê° ë¦¬ì†ŒìŠ¤ì˜ ì‹œê°„ë³„ ë¹„ìš©, ì‚¬ìš©ëŸ‰ ì§‘ê³„
    - BillingAccountId, ServiceName ë“± ë©”íƒ€ë°ì´í„° ìœ ì§€
    
    ì…ë ¥: time_normalized.csv (1ì‹œê°„ ë‹¨ìœ„ í™•ì¥ëœ ë°ì´í„°)
    ì¶œë ¥: resource_hourly_grouped.csv (ë¦¬ì†ŒìŠ¤ë³„ ì‹œê°„ ì§‘ê³„)

    """
    
    def __init__(self, config_path='config/focus_config.yaml'):
        """
        ì´ˆê¸°í™”
        
        Args:
            config_path (str): ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        super().__init__(config_path)
        
        data_config = self.config['data']
        self.input_path = Path(data_config['time_normalized_output'])
        self.output_path = Path(data_config['resource_grouped_output'])
        
        self.df = None
        self.df_grouped = None
    
    
    def load(self):
        """
        ì‹œê°„ ì •ê·œí™”ëœ ë°ì´í„° ë¡œë“œ
        
        Returns:
            self
        """
        self.print_step("ë°ì´í„° ë¡œë”©", f"{self.input_path}")
        
        if not self.input_path.exists():
            self.print_error(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.input_path}")
            raise FileNotFoundError(f"{self.input_path}")
        
        self.df = pl.read_csv(self.input_path, infer_schema_length=0)
        
        self.print_success(f"ë¡œë“œ ì™„ë£Œ: {len(self.df):,}ê±´")
        print(f"   ğŸ“‹ ì»¬ëŸ¼: {len(self.df.columns)}ê°œ")
        
        return self
    
    
    def _validate_columns(self):
        """
        í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦
        
        Returns:
            self
        """
        print("\nğŸ” í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦ ì¤‘...")
        
        required_cols = [
            'ResourceId',
            'HourlyTimestamp',
            'HourlyCost',
            'ServiceName',
            'BillingAccountId'
        ]
        
        missing = [col for col in required_cols if col not in self.df.columns]
        
        if missing:
            self.print_error(f"ëˆ„ë½ëœ ì»¬ëŸ¼: {missing}")
            raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}")
        
        self.print_success(f"í•„ìˆ˜ ì»¬ëŸ¼ ê²€ì¦ ì™„ë£Œ")
        
        return self
    
    
    def _convert_types(self):
        """
        ë°ì´í„° íƒ€ì… ë³€í™˜
        
        Returns:
            self:
        """
        print("\nğŸ”„ ë°ì´í„° íƒ€ì… ë³€í™˜ ì¤‘...")
        
        # HourlyTimestampë¥¼ datetimeìœ¼ë¡œ ë³€í™˜
        self.df = self.df.with_columns([
            pl.col('HourlyTimestamp').str.to_datetime(),
            pl.col('HourlyCost').cast(pl.Float64)
        ])
        
        if 'SimulatedCPUUsage' in self.df.columns:
            self.df = self.df.with_columns([
                pl.col('SimulatedCPUUsage').cast(pl.Float64),
                pl.col('SimulatedMemoryUsage').cast(pl.Float64)
            ])

        self.print_success("íƒ€ì… ë³€í™˜ ì™„ë£Œ")
        
        return self
    
    
    def process(self):
        """
        ë¦¬ì†ŒìŠ¤ë³„ ê·¸ë£¹í™” ìˆ˜í–‰
        
        ê·¸ë£¹í™” í‚¤:
        - ProviderName
        - BillingAccountId
        - ResourceId
        - HourlyTimestamp
        - ServiceName
        - Region (if there is) - option?
        
        ì§‘ê³„:
        - TotalHourlyCost: ì‹œê°„ë‹¹ ì´ ë¹„ìš©
        - RecordCount: í•´ë‹¹ ì‹œê°„ì˜ ë ˆì½”ë“œ ìˆ˜
        
        Returns:
            self
        """
        self.print_step("ë¦¬ì†ŒìŠ¤ë³„ ê·¸ë£¹í™” ì‹œì‘")
        
        print(f"   ì›ë³¸ ë ˆì½”ë“œ: {len(self.df):,}ê±´")
        
        # ê·¸ë£¹í™”í•  ì»¬ëŸ¼ ê²°ì •
        group_cols = [
            'ProviderName',
            'BillingAccountId',
            'ResourceId',
            'HourlyTimestamp',
            'ServiceName'
        ]
        
        # self.df_grouped = self.df.group_by(group_cols).agg([
        #     pl.col('HourlyCost').sum().alias('TotalHourlyCost'),
        #     pl.count().alias('RecordCount')
        # ])

        # ê·¸ë£¹í™” ë° ì§‘ê³„
        agg_exprs = [
            pl.col('HourlyCost').sum().alias('TotalHourlyCost'),
            pl.count().alias('RecordCount')
        ]
        
        if 'ResourceType' in self.df.columns:
            group_cols.append('ResourceType')

        # GCP: SimulatedCPUUsage, SimulatedMemoryUsage í‰ê· 
        if 'SimulatedCPUUsage' in self.df.columns:
            agg_exprs.extend([
                pl.col('SimulatedCPUUsage').mean().alias('AvgCPUUsage'),
                pl.col('SimulatedMemoryUsage').mean().alias('AvgMemoryUsage')
            ])

        # AWS: ConsumedQuantity í•©ê³„
        # if 'ConsumedQuantity' in self.df.columns:
        #     agg_exprs.append(
        #         pl.col('ConsumedQuantity').sum().alias('TotalConsumedQuantity')
        #     )

        self.df_grouped = self.df.group_by(group_cols).agg(agg_exprs)
        
        self.print_success(f"ê·¸ë£¹í™” ì™„ë£Œ: {len(self.df_grouped):,}ê±´")
        print(f"   ì••ì¶•ë¥ : {len(self.df) / len(self.df_grouped):.2f}x")
        
        # ìš”ì•½ í†µê³„
        self._print_summary()
        
        return self
    
    
    def _print_summary(self):
        """ê·¸ë£¹í™” ê²°ê³¼ ìš”ì•½ ì¶œë ¥"""

        print(f"\nğŸ“Š ê·¸ë£¹í™” ìš”ì•½:")
        if 'ProviderName' in self.df_grouped.columns:
            provider_stats = self.df_grouped.group_by('ProviderName').agg([
                pl.col('ResourceId').n_unique().alias('Resources'),
                pl.col('TotalHourlyCost').sum().alias('TotalCost')
            ])

            print(f"\n   â˜ï¸  Providerë³„:")
            for row in provider_stats.iter_rows(named=True):
                print(f"      â€¢ {row['ProviderName']}: {row['Resources']:,}ê°œ ë¦¬ì†ŒìŠ¤, ${row['TotalCost']:,.2f}")

        # ê³ ìœ  ë¦¬ì†ŒìŠ¤ ìˆ˜
        unique_resources = self.df_grouped.select('ResourceId').n_unique()
        print(f"   â€¢ ê³ ìœ  ë¦¬ì†ŒìŠ¤: {unique_resources:,}ê°œ")
        
        # ê³ ìœ  ë¹Œë§ ê³„ì • ìˆ˜
        unique_accounts = self.df_grouped.select('BillingAccountId').n_unique()
        print(f"   â€¢ ë¹Œë§ ê³„ì •: {unique_accounts:,}ê°œ")
        
        # ì‹œê°„ ë²”ìœ„
        min_time = self.df_grouped.select('HourlyTimestamp').min().item()
        max_time = self.df_grouped.select('HourlyTimestamp').max().item()
        print(f"   â€¢ ì‹œê°„ ë²”ìœ„: {min_time} ~ {max_time}")
        
        # ì´ ë¹„ìš©
        total_cost = self.df_grouped.select('TotalHourlyCost').sum().item()
        print(f"   â€¢ ì´ ë¹„ìš©: ${total_cost:,.2f}")
    
    
    def save(self):
        """
        ê·¸ë£¹í™” ê²°ê³¼ ì €ì¥
        
        Returns:
            self: ì²´ì´ë‹ ì§€ì›
        """
        if self.df_grouped is None:
            self.print_error("ê·¸ë£¹í™”ë¥¼ ë¨¼ì € ìˆ˜í–‰í•˜ì„¸ìš”: process()")
            raise ValueError("ê·¸ë£¹í™” ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤")
        
        self.print_step("ê²°ê³¼ ì €ì¥", f"{self.output_path}")
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        self.ensure_dir(self.output_path.parent)
        
        # CSV ì €ì¥
        self.df_grouped.write_csv(self.output_path)
        
        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size_mb = self.output_path.stat().st_size / 1024**2
        
        self.print_success("ì €ì¥ ì™„ë£Œ")
        print(f"   ğŸ“‚ ê²½ë¡œ: {self.output_path}")
        print(f"   ğŸ’¾ í¬ê¸°: {file_size_mb:.1f} MB")
        
        return self
    
    
    def run(self):
        """
        ì „ì²´ ê·¸ë£¹í™” í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰
        
        Returns:
            self
        """
        return (self.load()
                ._validate_columns()
                ._convert_types()
                .process()
                .save())
    
    
    def get_results(self):
        """
        ê·¸ë£¹í™” ê²°ê³¼ ë°˜í™˜
        
        Returns:
            tuple: (ê·¸ë£¹í™” ë°ì´í„°, ì¶œë ¥ ê²½ë¡œ)
        """
        return (self.df_grouped, self.output_path)


if __name__ == "__main__":
    
    print("\nğŸš€ ë¦¬ì†ŒìŠ¤ë³„ ê·¸ë£¹í™” ì‹œì‘")
    print("="*100)
    
    grouper = ResourceGrouper('config/focus_config.yaml')
    grouper.run()
    
    # ê²°ê³¼ ì¡°íšŒ
    df_grouped, output_path = grouper.get_results()
    
    print(f"\nâœ… ê·¸ë£¹í™” ì™„ë£Œ!")
    print(f"ğŸ“‚ ì¶œë ¥ íŒŒì¼: {output_path}")
    